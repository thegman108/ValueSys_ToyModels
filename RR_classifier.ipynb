{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: measure how correlated certain features of the policy $\\pi_0$ are to the value $P(URS | \\pi=\\pi_0)$, where $URS$ indicates that the policy was optimized for a random reward function $R \\in U[-1,1]^{|T|}$ (where $|T|$ is the number of transitions with non-zero probability). For simplicity's sake, we assume that it was either optimized for some $R$ or generated uniformly randomly from the set of all policies, with a 50% chance of each scenario. We also assume that the reward is generated i.i.d. via $R(s, a, s') \\sim N(0, 1)$.\n",
    "\n",
    "We can also analyze $P(USS | \\pi = \\pi_0)$ where $USS$ consists of sampling a sparsity factor $k \\in [1, |T|]$, then zeroing out $k$ values from a randomly sampled $R$ as before.\n",
    "\n",
    "***For outside observers: see the bottom two cells for how the graphs in our report were generated***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox as mdpt, numpy as np\n",
    "import mdptoolbox.example\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs with different parameters, sparsity\n",
    "from functools import partial\n",
    "\n",
    "NUM_MDPs = 100\n",
    "NUM_STATES = 10\n",
    "NUM_ACTIONS = 4\n",
    "\n",
    "def get_transition_matrix(num_states, num_actions, generator = np.random.dirichlet, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a determinstic transition matrix for a given number of states and actions\n",
    "    \n",
    "    Returns:\n",
    "        P: (num_actions, num_states, num_states) array, where P[a, s, s'] is the probability of \n",
    "        transitioning from state s to state s' given action a\n",
    "    \"\"\"\n",
    "    P = np.zeros((num_actions, num_states, num_states)) # (A, S, S') shape\n",
    "    for a in range(num_actions):\n",
    "        for s in range(num_states):\n",
    "            P[a, s, :] = generator(np.ones(num_states))\n",
    "    return P\n",
    "\n",
    "def get_reward_matrix(transitions, sparsity = 0.0, generator = partial(np.random.uniform, -1, 1), **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a reward matrix for a given number of states and actions\n",
    "    \"\"\"\n",
    "    num_pos_transitions = np.count_nonzero(transitions)\n",
    "    num_sparse_rewards = max(1, int(sparsity * num_pos_transitions))\n",
    "    rewards = np.array([(0 if i < num_sparse_rewards else generator()) for i in range(num_pos_transitions)])\n",
    "    np.random.shuffle(rewards) # create a random permutation of the rewards\n",
    "    # num_pos_transitions number of rewards, with num_sparse_rewards number of zeros\n",
    "    out = np.zeros(transitions.shape)\n",
    "    i = 0\n",
    "    for a, s, s_prime in np.argwhere(transitions):\n",
    "        out[a, s, s_prime] = rewards[i]\n",
    "        i += 1\n",
    "    assert np.count_nonzero(out) == num_pos_transitions - num_sparse_rewards\n",
    "    return out\n",
    "\n",
    "DISCOUNT = 0.9\n",
    "EPSILON = 0.01 # roughly indicates the \"skill level\" of the agent\n",
    "MAX_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tests(num_mdps = NUM_MDPs, sparsity_levels: np.ndarray = None, mdp_generator = mdpt.mdp.PolicyIterationModified, P_generator = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a bunch of MDPs with different sparsity levels, and return the sparsity levels and the MDPs\n",
    "\n",
    "    Args:\n",
    "        sparsity_levels: a list of sparsity levels to generate MDPs with\n",
    "    Returns:\n",
    "        sparsity_levels: the sparsity levels used to generate the MDPs, in the same order as the MDPs\n",
    "        MDPS: an array of MDPs\n",
    "    \"\"\"\n",
    "    (max_iter, epsilon) = (kwargs['max_iter'], kwargs['epsilon']) if 'max_iter' in kwargs and 'epsilon' in kwargs else (MAX_ITER, EPSILON)\n",
    "    sparsity_levels = sparsity_levels if sparsity_levels is not None else np.arange(num_mdps) / num_mdps\n",
    "    sparsity_copy = sparsity_levels.copy() # defensive copy\n",
    "    np.random.shuffle(sparsity_copy)\n",
    "    transitions = np.array([get_transition_matrix(NUM_STATES, NUM_ACTIONS, **kwargs) if P_generator is None else P_generator(NUM_STATES, NUM_ACTIONS, **kwargs) for i in range(num_mdps)])\n",
    "    \n",
    "    MDPS = np.array([mdp_generator(\n",
    "        transitions[i], \n",
    "        get_reward_matrix(transitions[i], sparsity_copy[i], **kwargs), \n",
    "        DISCOUNT, max_iter = max_iter) \n",
    "        for i in range(num_mdps)\n",
    "    ])\n",
    "    for mdp in MDPS:\n",
    "        if mdp_generator == mdpt.mdp.ValueIteration:\n",
    "            mdp.epsilon = epsilon\n",
    "    return sparsity_copy, MDPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a transition function with various settings for properties (e.g. deterministic, sparse, fixed) and train a classifier to predict P(URS | $\\pi = \\pi_0$) and P(USS | $\\pi = \\pi_0$) (baseline probability = 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs (with baseline/zero sparsity), solve some of them, \n",
    "# generate random policy for others\n",
    "\n",
    "def transition_function_sparse_loops(states, actions, fixed = False, **kwargs):\n",
    "    \"\"\"\n",
    "    Sparse transition function with guaranteed loops\n",
    "    TODO: possibly implement terminal states\n",
    "    \"\"\"\n",
    "    # print(fixed)\n",
    "    rng = np.random.default_rng(seed = 0) if fixed else None\n",
    "    transitions = np.zeros((actions, states, states))\n",
    "    for state in range(states):\n",
    "        self_loop = np.random.randint(0, actions) if not fixed else rng.integers(0, actions)\n",
    "        for action in range(actions):\n",
    "            if action == self_loop:\n",
    "                for next_state in range(states):\n",
    "                    transitions[action, state, next_state] = 1 if next_state == state else 0\n",
    "            else: # sparse randomness\n",
    "                transitions[action, state, :] = np.zeros(states)\n",
    "                transitions[action, state, np.random.randint(states) if not fixed else rng.integers(0, states)] = 1\n",
    "    return transitions\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "#sparsity_levels = np.zeros(NUM_MDPs)\n",
    "# URS would be np.zeros(NUM_MDPs)\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, NUM_MDPs // 2, replace = False) # The indices of the MDPs with random policies\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "MDPS = generate_tests(NUM_MDPs, sparsity_levels = sparsity_levels,\n",
    "                      P_generator = transition_function_sparse_loops, fixed = fixed)[1]\n",
    "# print(np.ndim(MDPS[0].R))\n",
    "# Problem with _bounditer in ValueIteration happening when upper uniform bound is too high/sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "for i in random_pol_indices:\n",
    "    MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([MDPS[1].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)])\n",
    "assert not fixed or np.all([np.all([MDPS[i].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)]) for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 1 3 3 1 0 1 1 1]\n",
      " [0 0 3 2 2 0 3 2 1 1]\n",
      " [1 3 2 2 3 3 3 1 0 3]\n",
      " [2 0 2 1 0 0 0 3 3 3]\n",
      " [2 0 0 3 0 3 0 2 2 2]\n",
      " [0 1 3 3 0 3 0 2 3 3]\n",
      " [0 2 2 3 0 0 0 0 3 3]\n",
      " [3 2 2 0 2 3 0 1 1 2]\n",
      " [2 3 2 3 3 2 2 3 3 2]\n",
      " [2 1 0 0 2 2 3 0 0 2]] [0 1 0 0 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(policies[0:10], random_or_rr[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "\n",
    "def regression(X, y, test_size = 0.2, regression = LinearRegression):\n",
    "    \"\"\"\n",
    "    Trains a linear regression model on the given data, and returns the model and test data\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model = regression().fit(X_train, y_train)\n",
    "    return model, model.predict_proba(X_test), y_test\n",
    "\n",
    "def neural_network(X, y, test_size = 0.2, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the given data, and returns the model and the mean squared error\n",
    "    \"\"\"\n",
    "    def build_model():\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation = 'relu', input_shape = [X.shape[1]]),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(64, activation = 'relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    model = build_model()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mae'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model.fit(X_train, y_train, epochs = 100, validation_split = 0.2, verbose = 1, \n",
    "              callbacks = [keras.callbacks.EarlyStopping(patience = 3)])\n",
    "    return model, model.predict(X_test), y_test\n",
    "\n",
    "def find_loop_dist_and_length(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Computes the distance to the loop and the length of the loop for a given policy and initial state\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "    \n",
    "    #distance to loop = visited_states[current_state]; loop length = step - visited_states[current_state]\n",
    "    return visited_states[current_state], step - visited_states[current_state]\n",
    "\n",
    "def takes_self_loop(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\" \n",
    "    Returns 1 if the policy takes a self loop, 0 otherwise\n",
    "    \"\"\"\n",
    "    return int(transitions[policy[initial_state]][initial_state][initial_state] > 0.5)\n",
    "\n",
    "def num_out_arrows(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Returns the sum of outgoing arrows for each state that the policy visits from the \n",
    "    initial state before reaching a loop\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "    out_arrows = 0\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "        out_arrows += np.count_nonzero(transitions[policy[current_state]][current_state])\n",
    "    return out_arrows\n",
    "\n",
    "### Generate features\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "# Drop first to avoid multicollinearity, large coefficients\n",
    "# encoder.fit(np.arange(NUM_ACTIONS))\n",
    "# print(encoder.categories_)\n",
    "\n",
    "### Train the model\n",
    "policies_encoded = encoder.fit_transform(policies)\n",
    "features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                      for i in range(NUM_MDPs)])\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES) for x in range(2)] \n",
    "                         for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-entropy loss: 0.4363690283060056\n",
      "Accuracy: 0.8125\n",
      "Baseline log loss: 0.6931471805599454\n",
      "Model coefficients, intercept: [[ 1.95546857e-01  2.66547547e-01  2.46973453e-01  2.95588200e-01\n",
      "   4.34011137e-01  7.18055457e-03  3.22190959e-01 -4.74514387e-01\n",
      "   3.28747867e-01  3.06324300e-01  7.28899337e-02 -4.97649820e-02\n",
      "   1.11398995e-01 -1.22775902e-01  7.09198689e-01 -4.90435144e-02\n",
      "   5.47633723e-01  4.86472455e-01  3.35243921e-01  1.40629064e-01\n",
      "   2.56244124e-01  1.40181275e-02  2.26780767e-01 -3.77630103e-01\n",
      "  -5.37952266e-01  4.38326633e-01  3.74973272e-01  1.88890014e-01\n",
      "   1.53864132e-01  1.01198858e-01  1.96076780e-01 -2.11299302e-01\n",
      "  -3.38350343e-02  3.32146849e-01  4.54173983e-01  3.14797263e-01\n",
      "   1.76379702e-01 -8.82470373e-04  3.57047310e-01  1.18595234e-01\n",
      "  -4.62806003e-01  2.58636427e-01  4.66727711e-01  2.11768123e-01\n",
      "   2.93951895e-02  3.00746711e-01 -1.31422983e-01  1.13767350e-01\n",
      "  -1.15465738e-02  5.89000733e-01  4.33277175e-01  4.31373124e-01\n",
      "   1.84950851e-01  1.49978467e-01 -1.10058541e-01 -3.68946307e-01\n",
      "  -1.79630662e-01  1.69226902e-01  2.74127551e-01  1.80725307e-01\n",
      "  -1.49686729e-01 -1.58911783e-02  3.05844800e-01  7.00646688e-01\n",
      "  -5.83954124e-02  4.23103832e-01  5.11719927e-01  5.27828381e-01\n",
      "   2.50116621e-01  3.13272644e-01  1.79104804e-01 -3.00090962e-01\n",
      "  -8.05592473e-01  0.00000000e+00  3.13180169e-01  3.79501236e-01\n",
      "   1.52607507e-01  1.32531523e-01 -1.05619044e-01  1.23793653e-01\n",
      "   3.36540830e-02  4.08517019e-01 -9.60599515e-02 -1.29357475e+00\n",
      "  -1.30702582e+00 -1.09149024e+00 -1.20824578e+00 -1.28950230e+00\n",
      "  -1.23812239e+00 -1.12999527e+00 -1.40664836e+00 -1.09951320e+00\n",
      "  -1.34215662e+00]] [0.10811531]\n",
      "Sample outputs: [(array([0.84704003, 0.15295997]), 0), (array([0.3929803, 0.6070197]), 1), (array([0.326147, 0.673853]), 0), (array([0.10191022, 0.89808978]), 1), (array([0.04340672, 0.95659328]), 1), (array([0.20183443, 0.79816557]), 0), (array([0.11575177, 0.88424823]), 1), (array([0.04528879, 0.95471121]), 1), (array([0.34753891, 0.65246109]), 1), (array([0.48371315, 0.51628685]), 1)]\n"
     ]
    }
   ],
   "source": [
    "# features = np.concatenate((encoder.fit_transform(policies), encoder.fit_transform(loop_lengths),\n",
    "#                            ), axis = 1)\n",
    "# print(loop_lengths[0:10])\n",
    "features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "model, y_pred, y_test = regression(features, random_or_rr, regression = partial(LogisticRegression, max_iter = 1000))\n",
    "print(\"Average cross-entropy loss:\", log_loss(y_test, y_pred, normalize = True))\n",
    "print(\"Accuracy:\", np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])) \n",
    "\n",
    "# if round(y_pred[0]) is 0, then model thinks 1 is more likely; if 1, then 0 is more likely\n",
    "# print(y_pred)\n",
    "print(\"Baseline log loss:\", log_loss(y_test, np.full(y_pred.shape, 0.5), normalize = True))\n",
    "print(\"Model coefficients, intercept:\", model.coef_, model.intercept_)\n",
    "print(\"Sample outputs:\", [(y_pred[i], y_test[i]) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [3 3 0 1 3 1 1 3 3 2] Probability: [0.02236499 0.97763501] Actual: 0\n",
      "Policy: [0 2 2 0 2 0 2 0 1 0] Probability: [0.02184298 0.97815702] Actual: 1\n",
      "Policy: [1 1 1 3 2 1 2 0 1 0] Probability: [0.0209111 0.9790889] Actual: 1\n",
      "Policy: [0 2 0 2 1 1 1 3 3 2] Probability: [0.02083051 0.97916949] Actual: 1\n",
      "Policy: [0 2 2 3 2 3 0 3 2 1] Probability: [0.01571642 0.98428358] Actual: 1\n",
      "Policy: [0 0 0 0 0 1 0 0 0 0] Probability: [9.99896234e-01 1.03766445e-04] Actual: 0\n",
      "Policy: [3 1 1 2 2 1 1 3 1 0] Probability: [9.99885602e-01 1.14398092e-04] Actual: 0\n",
      "Policy: [0 3 3 1 0 3 2 1 3 3] Probability: [9.99883389e-01 1.16611460e-04] Actual: 0\n",
      "Policy: [1 2 2 3 2 0 0 1 0 2] Probability: [9.99523022e-01 4.76978209e-04] Actual: 0\n",
      "Policy: [1 2 1 3 1 3 0 0 2 1] Probability: [9.99510443e-01 4.89557379e-04] Actual: 0\n"
     ]
    }
   ],
   "source": [
    "### Grab the five policies with the highest and lowest probabilities of being random\n",
    "import networkx as nx\n",
    "\n",
    "if fixed:\n",
    "    # Generate a graph of the first MDP\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(NUM_STATES):\n",
    "        G.add_node(i)\n",
    "    enumerated_edges = {}\n",
    "    for i in range(NUM_ACTIONS):\n",
    "        enumerated_edges[i] = []\n",
    "        for j in range(NUM_STATES):\n",
    "            for k in range(NUM_STATES):\n",
    "                if MDPS[0].P[i][j, k] == 1:\n",
    "                    G.add_edge(j, k, action = i)\n",
    "                    enumerated_edges[i].append((j, k))\n",
    "    edge_labels = {(u, v): f\"{d['action']}\" for u, v, d in G.edges(data=True)}\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=20)  # k: Optimal distance between nodes. Increase/decrease to spread nodes out\n",
    "    nx.draw(G, pos = pos, with_labels = True)\n",
    "    nx.draw_networkx_edge_labels(G, pos = pos, edge_labels = edge_labels)\n",
    "    \n",
    "    for i in range(NUM_ACTIONS):\n",
    "        print(f\"Action {i} transitions:\", enumerated_edges[i])\n",
    "\n",
    "highest_probs = np.argsort(y_pred[:, 1])[-5:]\n",
    "lowest_probs = np.argsort(y_pred[:, 1])[:5]\n",
    "#print(\"Highest probabilities:\", [(y_pred[i], y_test[i]) for i in highest_probs])\n",
    "for i in np.concatenate((highest_probs, lowest_probs)):\n",
    "    print(\"Policy:\", policies[i], \"Probability:\", y_pred[i], \"Actual:\", y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On a random deterministic MDP(s), it doesn't seem like URS is identifiable, which is perhaps to be expected as every policy is optimal for some (normalized) reward function\n",
    "    - This also matches our results when looking at the distribution of optimal policies for \"cloud\"-y MDPs\n",
    "- As a control, with MDPs with loops, passing in just the policy (which shouldn't give much information without the related MDP) gives 0.54 accuracy\n",
    "    - Why not 0.50 exactly?\n",
    "    - Similar results with neural network\n",
    "    - This holds true when we use the label predictions for regression (model.predict), as well as the probability prediction (model.predict_proba)\n",
    "- Passing in the policy with the transition function (flattened) gives 0.53 accuracy, even with the NN\n",
    "    - Would likely need a graph neural network to train deep enough \"circuits\" to use the data of the whole transition function effectively\n",
    "- Distance to loop correlates somewhat well with P(URS) (~0.66-0.68 accuracy, 0.61-0.63 log loss on a diverse dataset of sparse transition functions), length of loop not as well (~0.56 accuracy, 0.687 log loss)\n",
    "    - Putting them together doesn't give improvement (~0.67-0.71 accuracy, 0.57-0.62 log loss)\n",
    "    - Intuitively, the length of the loop an optimal policy takes is its “goal complexity”; distance to loop = “agency” \n",
    "- Setting $k \\in U[1, N/2]$ gives:\n",
    "    - 0.56 accuracy, 0.688 log loss with length of loop; 0.66-0.672 accuracy, 0.61 log loss with distance to loop\n",
    "    - Setting the upper bound of $k$ too high results in some weird MDP package errors, I suspect because sparsity is too high\n",
    "    - This matches the distribution results we found in reward_function.ipynb, as sparsity didn't seem to \"matter\" until around ~0.9 given (S, A) = (10, 4)\n",
    "- $k \\in U[1, N]$ gives similar results\n",
    "    - (Note that this was run with PolicyIterationModified instead of ValueIteration with the same settings, which I don't expect to change any of the results, but I might be wrong)\n",
    "    - 0.72-0.74 accuracy with policy, distance to loop, and length of loop\n",
    "- Calculating whether the policy enters a self loop or not for each state $s$ gives 0.80 accuracy, 0.43 log loss!\n",
    "    - With policy and distance to loop included, ~0.82-0.84 accuracy, 0.38-0.40 log loss\n",
    "    - Similar results with neural network\n",
    "    - The logistic coefficients are all negative, lending evidence to the claim that a policy that takes more self-loops is *less* likely to be sampled via URS or USS\n",
    "        - 0.9999 chance of being from UPS if the policy always takes self-loops; 0.95 chance of being from URS/USS if it never takes self-loops\n",
    "- Calculating out-arrows also gives ~0.80 accuracy, 0.44 log loss\n",
    "    - Combining with self-loops doesn't give much\n",
    "    - Coefficients are positive --> a policy that reaches more out-arrows is more likely to be sampled via URS or USS\n",
    "- P(USS) / P(URS) is really difficult (basically 0.5)\n",
    "- Graph results (see plt plot below) fits for P(USS) given uniform k, P(URS)\n",
    "- Apparently when there is only one reward, passing in policy is *more* predictive than LL or O,S (.77 acc, .45 LL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the model's performance\n",
    "### This is the cell that generated the plots in our reports\n",
    "\n",
    "num_runs = 90\n",
    "accuracies = np.zeros((num_runs // 3, 3))\n",
    "log_losses = np.zeros((num_runs // 3, 3))\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "# sparsity_levels = np.random.uniform(1.0 - 1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "# sparsity_levels = np.zeros(NUM_MDPs)\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, NUM_MDPs // 2, replace = False) \n",
    "# The indices of the MDPs with random policies (or random dense rewards)\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "# to measure P(USS) / P(URS), \n",
    "# let sparsity_levels = [sparsity_levels[i] if i in random_pol_set else 0 for i in range(NUM_MDPs)]\n",
    "MDPS = generate_tests(NUM_MDPs, sparsity_levels = sparsity_levels,\n",
    "                    P_generator = transition_function_sparse_loops, fixed = fixed)[1]\n",
    "\n",
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "for i in random_pol_indices: #comment out when measuring P(USS) / P(URS)\n",
    "    MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR\n",
    "\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES)\n",
    "                           for x in range(2)] for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "\n",
    "for n in range(num_runs):\n",
    "    ### Train the model\n",
    "    policies_encoded = encoder.fit_transform(policies)\n",
    "    features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                        for i in range(NUM_MDPs)])\n",
    "\n",
    "    if n % 3 == 2:\n",
    "        features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "    elif n % 3 == 1:\n",
    "        features = encoder.fit_transform(loop_lengths)\n",
    "    model, y_pred, y_test = regression(features, random_or_rr, regression=partial(LogisticRegression, max_iter=MAX_ITER))\n",
    "    accuracy = np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])\n",
    "    log_loss_value = log_loss(y_test, y_pred, normalize=True)\n",
    "    accuracies[n // 3][n % 3] = accuracy\n",
    "    log_losses[n // 3][n % 3] = log_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(np.array([x for pair in zip(accuracies.T, log_losses.T) for x in pair]).T, labels=\n",
    "            ['Accuracy (P)', 'Log Loss (P)', 'Accuracy (LL)', 'Log Loss (LL)', 'Accuracy (O,S)', 'Log Loss (O,S)'])\n",
    "plt.title('Regression Performances with Different Features')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
