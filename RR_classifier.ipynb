{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: measure how correlated certain features of the policy $\\pi_0$ are to the value $P(URS | \\pi=\\pi_0)$, where $URS$ indicates that the policy was optimized for a random reward function $R \\in U[-1,1]^{|T|}$ (where $|T|$ is the number of transitions with non-zero probability). For simplicity's sake, we assume that it was either optimized for some $R$ or generated uniformly randomly from the set of all policies, with a 50% chance of each scenario. We also assume that the reward is generated i.i.d. via $R(s, a, s') \\sim N(0, 1)$.\n",
    "\n",
    "We can also analyze $P(USS | \\pi = \\pi_0)$ where $USS$ consists of sampling a sparsity factor $k \\in [1, |T|]$, then zeroing out $k$ values from a randomly sampled $R$ as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox as mdpt, numpy as np\n",
    "import mdptoolbox.example\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs with different parameters, sparsity\n",
    "from functools import partial\n",
    "\n",
    "NUM_MDPs = 100\n",
    "NUM_STATES = 10\n",
    "NUM_ACTIONS = 4\n",
    "\n",
    "def get_transition_matrix(num_states, num_actions, generator = np.random.dirichlet, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a determinstic transition matrix for a given number of states and actions\n",
    "    \n",
    "    Returns:\n",
    "        P: (num_actions, num_states, num_states) array, where P[a, s, s'] is the probability of \n",
    "        transitioning from state s to state s' given action a\n",
    "    \"\"\"\n",
    "    P = np.zeros((num_actions, num_states, num_states)) # (A, S, S') shape\n",
    "    for a in range(num_actions):\n",
    "        for s in range(num_states):\n",
    "            P[a, s, :] = generator(np.ones(num_states))\n",
    "    return P\n",
    "\n",
    "def get_reward_matrix(transitions, sparsity = 0.0, generator = partial(np.random.uniform, -1, 1), **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a reward matrix for a given number of states and actions\n",
    "    \"\"\"\n",
    "    num_pos_transitions = np.count_nonzero(transitions)\n",
    "    num_sparse_rewards = max(1, int(sparsity * num_pos_transitions))\n",
    "    rewards = np.array([(0 if i < num_sparse_rewards else generator()) for i in range(num_pos_transitions)])\n",
    "    np.random.shuffle(rewards) # create a random permutation of the rewards\n",
    "    # num_pos_transitions number of rewards, with num_sparse_rewards number of zeros\n",
    "    out = np.zeros(transitions.shape)\n",
    "    i = 0\n",
    "    for a, s, s_prime in np.argwhere(transitions):\n",
    "        out[a, s, s_prime] = rewards[i]\n",
    "        i += 1\n",
    "    assert np.count_nonzero(out) == num_pos_transitions - num_sparse_rewards\n",
    "    return out\n",
    "\n",
    "DISCOUNT = 0.9\n",
    "EPSILON = 0.01 # roughly indicates the \"skill level\" of the agent\n",
    "MAX_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tests(num_mdps = NUM_MDPs, sparsity_levels: np.ndarray = None, mdp_generator = mdpt.mdp.PolicyIterationModified, P_generator = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a bunch of MDPs with different sparsity levels, and return the sparsity levels and the MDPs\n",
    "\n",
    "    Args:\n",
    "        sparsity_levels: a list of sparsity levels to generate MDPs with\n",
    "    Returns:\n",
    "        sparsity_levels: the sparsity levels used to generate the MDPs, in the same order as the MDPs\n",
    "        MDPS: an array of MDPs\n",
    "    \"\"\"\n",
    "    (max_iter, epsilon) = (kwargs['max_iter'], kwargs['epsilon']) if 'max_iter' in kwargs and 'epsilon' in kwargs else (MAX_ITER, EPSILON)\n",
    "    sparsity_levels = sparsity_levels if sparsity_levels is not None else np.arange(num_mdps) / num_mdps\n",
    "    sparsity_copy = sparsity_levels.copy() # defensive copy\n",
    "    np.random.shuffle(sparsity_copy)\n",
    "    transitions = np.array([get_transition_matrix(NUM_STATES, NUM_ACTIONS, **kwargs) if P_generator is None else P_generator(NUM_STATES, NUM_ACTIONS, **kwargs) for i in range(num_mdps)])\n",
    "    \n",
    "    MDPS = np.array([mdp_generator(\n",
    "        transitions[i], \n",
    "        get_reward_matrix(transitions[i], sparsity_copy[i], **kwargs), \n",
    "        DISCOUNT, max_iter = max_iter) \n",
    "        for i in range(num_mdps)\n",
    "    ])\n",
    "    for mdp in MDPS:\n",
    "        if mdp_generator == mdpt.mdp.ValueIteration:\n",
    "            mdp.epsilon = epsilon\n",
    "    return sparsity_copy, MDPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a transition function with various settings for properties (e.g. deterministic, sparse, fixed) and train a classifier to predict URS | $\\pi = \\pi_0$ (baseline probability = 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs (with baseline/zero sparsity), solve some of them, \n",
    "# generate random policy for others\n",
    "\n",
    "def transition_function_sparse_loops(states, actions, fixed = False, **kwargs):\n",
    "    \"\"\"\n",
    "    Sparse transition function with guaranteed loops\n",
    "    TODO: possibly implement terminal states\n",
    "    \"\"\"\n",
    "    # print(fixed)\n",
    "    rng = np.random.default_rng(seed = 0) if fixed else None\n",
    "    transitions = np.zeros((actions, states, states))\n",
    "    for state in range(states):\n",
    "        self_loop = np.random.randint(0, actions) if not fixed else rng.integers(0, actions)\n",
    "        for action in range(actions):\n",
    "            if action == self_loop:\n",
    "                for next_state in range(states):\n",
    "                    transitions[action, state, next_state] = 1 if next_state == state else 0\n",
    "            else: # sparse randomness\n",
    "                transitions[action, state, :] = np.zeros(states)\n",
    "                transitions[action, state, np.random.randint(states) if not fixed else rng.integers(0, states)] = 1\n",
    "    return transitions\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "#sparsity_levels = np.zeros(NUM_MDPs)\n",
    "# URS would be np.zeros(NUM_MDPs)\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, int(NUM_MDPs / 2), replace = False) # The indices of the MDPs with random policies\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "MDPS = generate_tests(NUM_MDPs, sparsity_levels = sparsity_levels,\n",
    "                      P_generator = transition_function_sparse_loops, fixed = fixed)[1]\n",
    "# print(np.ndim(MDPS[0].R))\n",
    "# Problem with _bounditer in ValueIteration happening when upper uniform bound is too high/sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "for i in random_pol_indices:\n",
    "    MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([MDPS[1].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)])\n",
    "assert not fixed or np.all([np.all([MDPS[i].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)]) for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 3 0 0 2 1 3 3]\n",
      " [1 0 1 0 0 0 1 0 2 2]\n",
      " [1 0 1 3 1 2 2 2 0 0]\n",
      " [1 0 2 2 1 0 2 2 0 1]\n",
      " [0 2 2 2 2 0 0 2 1 3]\n",
      " [0 0 3 0 0 1 1 0 0 1]\n",
      " [1 1 0 1 2 0 2 1 0 0]\n",
      " [2 2 3 3 2 3 3 2 0 3]\n",
      " [1 0 1 0 3 1 0 3 3 2]\n",
      " [0 0 2 0 3 0 2 2 2 1]] [0 1 1 1 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(policies[0:10], random_or_rr[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "\n",
    "def regression(X, y, test_size = 0.2, regression = LinearRegression):\n",
    "    \"\"\"\n",
    "    Trains a linear regression model on the given data, and returns the model and test data\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model = regression().fit(X_train, y_train)\n",
    "    return model, model.predict_proba(X_test), y_test\n",
    "\n",
    "def neural_network(X, y, test_size = 0.2, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the given data, and returns the model and the mean squared error\n",
    "    \"\"\"\n",
    "    def build_model():\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation = 'relu', input_shape = [X.shape[1]]),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(64, activation = 'relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    model = build_model()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mae'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model.fit(X_train, y_train, epochs = 100, validation_split = 0.2, verbose = 1, \n",
    "              callbacks = [keras.callbacks.EarlyStopping(patience = 3)])\n",
    "    return model, model.predict(X_test), y_test\n",
    "\n",
    "def find_loop_dist_and_length(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Computes the distance to the loop and the length of the loop for a given policy and initial state\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "    \n",
    "    #distance to loop = visited_states[current_state]; loop length = step - visited_states[current_state]\n",
    "    return visited_states[current_state], step - visited_states[current_state]\n",
    "\n",
    "def takes_self_loop(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\" \n",
    "    Returns 1 if the policy takes a self loop, 0 otherwise\n",
    "    \"\"\"\n",
    "    return int(transitions[policy[initial_state]][initial_state][initial_state] > 0.5)\n",
    "\n",
    "def num_out_arrows(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Returns the sum of outgoing arrows for each state that the policy visits from the \n",
    "    initial state before reaching a loop\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "    out_arrows = 0\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "        out_arrows += np.count_nonzero(transitions[policy[current_state]][current_state])\n",
    "    return out_arrows\n",
    "\n",
    "### Generate features\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "# Drop first to avoid multicollinearity, large coefficients\n",
    "# encoder.fit(np.arange(NUM_ACTIONS))\n",
    "# print(encoder.categories_)\n",
    "\n",
    "### Train the model\n",
    "policies_encoded = encoder.fit_transform(policies)\n",
    "features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                      for i in range(NUM_MDPs)])\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES) for x in range(2)] \n",
    "                         for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-entropy loss: 0.42391483087956155\n",
      "Accuracy: 0.813\n",
      "Baseline log loss: 0.6931471805599454\n",
      "Model coefficients, intercept: [[ 3.03961485e-01  2.97586531e-01  2.62080652e-01  1.35112469e-01\n",
      "   2.14286429e-01  4.62192760e-03  7.32581390e-02  1.55434988e-01\n",
      "   3.15008390e-01  3.13906358e-01  2.73764650e-01  6.05475176e-02\n",
      "  -7.35769878e-02  8.42021436e-01 -6.85430430e-02 -4.90698597e-01\n",
      "   3.68483430e-01  3.36184269e-01  2.96177462e-01  1.98113208e-01\n",
      "   5.29665370e-02 -1.05475547e-03  3.50603293e-01 -5.68515001e-01\n",
      "   1.89644730e-01  4.91098889e-01  3.12858176e-01  3.21420159e-01\n",
      "   1.99877438e-01 -9.23429681e-02 -8.75744068e-02 -1.70162928e-01\n",
      "   2.55013872e-01  2.75473327e-01  2.87785985e-01  4.52123427e-05\n",
      "   1.38495322e-01 -6.94435467e-02 -8.36470427e-02  1.20722312e+00\n",
      "  -2.29671941e-01  4.04336060e-01  5.59831173e-01  2.35414714e-01\n",
      "  -4.35013185e-03  4.12247573e-02 -1.11240667e-01  3.31585249e-01\n",
      "  -2.14478228e-01  2.78405911e-01  2.70014228e-01  9.44175486e-02\n",
      "   4.44343090e-02 -9.78158506e-02 -3.67303334e-02  6.20139573e-01\n",
      "   1.86269628e-01  5.22680607e-01  3.94193332e-01  2.81333714e-01\n",
      "   2.04133503e-01  7.84582250e-02  2.59041082e-01 -2.36459230e-01\n",
      "  -6.40013446e-02 -3.97953907e-01  2.39375631e-01  3.46128042e-01\n",
      "   1.59536439e-01 -6.14582964e-02  1.18031759e-01  4.86141929e-03\n",
      "   5.07666826e-01  1.55723771e-01  4.77228200e-01  3.55237556e-01\n",
      "   2.81691942e-01  1.91909254e-01  3.15128981e-01 -3.36883772e-01\n",
      "   4.86980443e-01 -6.10517861e-01  0.00000000e+00 -1.43702184e+00\n",
      "  -1.16310894e+00 -1.21328239e+00 -1.22086745e+00 -1.51693966e+00\n",
      "  -1.23300214e+00 -1.34981423e+00 -1.03210520e+00 -1.46054481e+00\n",
      "  -1.15145396e+00]] [0.38653712]\n",
      "Sample outputs: [(array([0.2284465, 0.7715535]), 0), (array([0.17947348, 0.82052652]), 1), (array([0.0664876, 0.9335124]), 1), (array([0.98108146, 0.01891854]), 0), (array([0.11203101, 0.88796899]), 1), (array([0.94425484, 0.05574516]), 0), (array([0.06487996, 0.93512004]), 1), (array([0.07491568, 0.92508432]), 1), (array([0.45354785, 0.54645215]), 0), (array([0.10256053, 0.89743947]), 1)]\n"
     ]
    }
   ],
   "source": [
    "# features = np.concatenate((encoder.fit_transform(policies), encoder.fit_transform(loop_lengths),\n",
    "#                            ), axis = 1)\n",
    "# print(loop_lengths[0:10])\n",
    "features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "model, y_pred, y_test = regression(features, random_or_rr, regression = partial(LogisticRegression, max_iter = 1000))\n",
    "print(\"Average cross-entropy loss:\", log_loss(y_test, y_pred, normalize = True))\n",
    "print(\"Accuracy:\", np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])) \n",
    "\n",
    "# if round(y_pred[0]) is 0, then model thinks 1 is more likely; if 1, then 0 is more likely\n",
    "# print(y_pred)\n",
    "print(\"Baseline log loss:\", log_loss(y_test, np.full(y_pred.shape, 0.5), normalize = True))\n",
    "print(\"Model coefficients, intercept:\", model.coef_, model.intercept_)\n",
    "print(\"Sample outputs:\", [(y_pred[i], y_test[i]) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [0 0 2 2 2 0 3 2 0 3] Probability: [0.14126505 0.85873495] Actual: 1\n",
      "Policy: [1 0 2 3 2 3 2 0 1 1] Probability: [0.13567779 0.86432221] Actual: 1\n",
      "Policy: [2 0 0 0 1 3 1 0 2 0] Probability: [0.13082551 0.86917449] Actual: 1\n",
      "Policy: [0 0 3 3 2 1 2 2 0 2] Probability: [0.13049808 0.86950192] Actual: 1\n",
      "Policy: [3 3 3 1 0 1 1 1 3 2] Probability: [0.08836382 0.91163618] Actual: 1\n",
      "Policy: [1 0 2 2 2 3 0 0 1 2] Probability: [0.8658411 0.1341589] Actual: 1\n",
      "Policy: [1 0 3 2 3 2 1 2 1 1] Probability: [0.86565443 0.13434557] Actual: 1\n",
      "Policy: [3 1 2 1 0 2 3 1 1 1] Probability: [0.84712528 0.15287472] Actual: 1\n",
      "Policy: [0 1 1 2 3 2 2 3 3 0] Probability: [0.8466504 0.1533496] Actual: 1\n",
      "Policy: [0 2 0 1 1 1 3 0 3 3] Probability: [0.83482429 0.16517571] Actual: 0\n"
     ]
    }
   ],
   "source": [
    "### Grab the five policies with the highest and lowest probabilities of being random\n",
    "import networkx as nx\n",
    "\n",
    "if fixed:\n",
    "    # Generate a graph of the first MDP\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(NUM_STATES):\n",
    "        G.add_node(i)\n",
    "    enumerated_edges = {}\n",
    "    for i in range(NUM_ACTIONS):\n",
    "        enumerated_edges[i] = []\n",
    "        for j in range(NUM_STATES):\n",
    "            for k in range(NUM_STATES):\n",
    "                if MDPS[0].P[i][j, k] == 1:\n",
    "                    G.add_edge(j, k, action = i)\n",
    "                    enumerated_edges[i].append((j, k))\n",
    "    edge_labels = {(u, v): f\"{d['action']}\" for u, v, d in G.edges(data=True)}\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=20)  # k: Optimal distance between nodes. Increase/decrease to spread nodes out\n",
    "    nx.draw(G, pos = pos, with_labels = True)\n",
    "    nx.draw_networkx_edge_labels(G, pos = pos, edge_labels = edge_labels)\n",
    "    \n",
    "    for i in range(NUM_ACTIONS):\n",
    "        print(f\"Action {i} transitions:\", enumerated_edges[i])\n",
    "\n",
    "highest_probs = np.argsort(y_pred[:, 1])[-5:]\n",
    "lowest_probs = np.argsort(y_pred[:, 1])[:5]\n",
    "#print(\"Highest probabilities:\", [(y_pred[i], y_test[i]) for i in highest_probs])\n",
    "for i in np.concatenate((highest_probs, lowest_probs)):\n",
    "    print(\"Policy:\", policies[i], \"Probability:\", y_pred[i], \"Actual:\", y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On a random deterministic MDP(s), it doesn't seem like URS is identifiable, which is perhaps to be expected as every policy is optimal for some (normalized) reward function\n",
    "    - This also matches our results when looking at the distribution of optimal policies for \"cloud\"-y MDPs\n",
    "- As a control, with MDPs with loops, passing in just the policy (which shouldn't give much information without the related MDP) gives 0.54 accuracy\n",
    "    - Why not 0.50 exactly?\n",
    "    - Similar results with neural network\n",
    "    - This holds true when we use the label predictions for regression (model.predict), as well as the probability prediction (model.predict_proba)\n",
    "- Passing in the policy with the transition function (flattened) gives 0.53 accuracy, even with the NN\n",
    "    - Would likely need a graph neural network to train deep enough \"circuits\" to use the data of the whole transition function effectively\n",
    "- Distance to loop correlates somewhat well with P(URS) (~0.66-0.68 accuracy, 0.61-0.63 log loss on a diverse dataset of sparse transition functions), length of loop not as well (~0.56 accuracy, 0.687 log loss)\n",
    "    - Putting them together doesn't give improvement (~0.67-0.71 accuracy, 0.57-0.62 log loss)\n",
    "    - Intuitively, the length of the loop an optimal policy takes is its “goal complexity”; distance to loop = “agency” \n",
    "- Setting $k \\in U[1, N/2]$ gives:\n",
    "    - 0.56 accuracy, 0.688 log loss with length of loop; 0.66-0.672 accuracy, 0.61 log loss with distance to loop\n",
    "    - Setting the upper bound of $k$ too high results in some weird MDP package errors, I suspect because sparsity is too high\n",
    "    - This matches the distribution results we found in reward_function.ipynb, as sparsity didn't seem to \"matter\" until around ~0.9 given (S, A) = (10, 4)\n",
    "- $k \\in U[1, N]$ gives similar results\n",
    "    - (Note that this was run with PolicyIterationModified instead of ValueIteration with the same settings, which I don't expect to change any of the results, but I might be wrong)\n",
    "    - 0.72-0.74 accuracy with policy, distance to loop, and length of loop\n",
    "- Calculating whether the policy enters a self loop or not for each state $s$ gives 0.80 accuracy, 0.43 log loss!\n",
    "    - With policy and distance to loop included, ~0.82-0.84 accuracy, 0.38-0.40 log loss\n",
    "    - Similar results with neural network\n",
    "    - Surprisingly, the logistic coefficients are all negative, meaning that a policy that takes more self-loops is *less* likely to be sampled via URS or USS\n",
    "        - 0.9999 chance of being from UPS if the policy always takes self-loops; 0.95 chance of being from URS/USS if it never takes self-loops\n",
    "- Calculating out-arrows also gives ~0.80 accuracy, 0.44 log loss\n",
    "    - Combining with self-loops doesn't give much\n",
    "- TODO: run these tests multiple times to make box plots in the writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the model's performance\n",
    "\n",
    "num_runs = 90\n",
    "accuracies = np.zeros((int(num_runs / 3), 3))\n",
    "log_losses = np.zeros((int(num_runs / 3), 3))\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "#sparsity_levels = np.zeros(NUM_MDPs)\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, int(NUM_MDPs / 2), replace = False) # The indices of the MDPs with random policies\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "MDPS = generate_tests(NUM_MDPs, sparsity_levels = sparsity_levels,\n",
    "                    P_generator = transition_function_sparse_loops, fixed = fixed)[1]\n",
    "\n",
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "for i in random_pol_indices:\n",
    "    MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR\n",
    "\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES)\n",
    "                           for x in range(2)] for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "\n",
    "for n in range(num_runs):\n",
    "    ### Train the model\n",
    "    policies_encoded = encoder.fit_transform(policies)\n",
    "    features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                        for i in range(NUM_MDPs)])\n",
    "\n",
    "    if n % 3 == 2:\n",
    "        features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "    elif n % 3 == 1:\n",
    "        features = encoder.fit_transform(loop_lengths)\n",
    "    model, y_pred, y_test = regression(features, random_or_rr, regression=partial(LogisticRegression, max_iter=MAX_ITER))\n",
    "    accuracy = np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])\n",
    "    log_loss_value = log_loss(y_test, y_pred, normalize=True)\n",
    "    accuracies[n // 3][n % 3] = accuracy\n",
    "    log_losses[n // 3][n % 3] = log_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(np.array([x for pair in zip(accuracies.T, log_losses.T) for x in pair]).T, labels=\n",
    "            ['Accuracy (P)', 'Log Loss (P)', 'Accuracy (LL)', 'Log Loss (LL)', 'Accuracy (O,S)', 'Log Loss (O,S)'])\n",
    "plt.title('Regression Performances with Different Features')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
