{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: measure how correlated certain features of the policy $\\pi_0$ are to the value $P(URS | \\pi=\\pi_0)$, where $URS$ indicates that the policy was optimized for a random reward function $R \\in U[-1,1]^{|T|}$ (where $|T|$ is the number of transitions with non-zero probability). For simplicity's sake, we assume that it was either optimized for some $R$ or generated uniformly randomly from the set of all policies, with a 50% chance of each scenario. We also assume that the reward is generated i.i.d. via $R(s, a, s') \\sim N(0, 1)$.\n",
    "\n",
    "We can also analyze $P(USS | \\pi = \\pi_0)$ where $USS$ consists of sampling a sparsity factor $k \\in [1, |T|]$, then zeroing out $k$ values from a randomly sampled $R$ as before.\n",
    "\n",
    "***For outside observers: this is an experimental copy; see RR_classifier [original] for experiment results***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox as mdpt, numpy as np\n",
    "import mdptoolbox.example\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs with different parameters, sparsity\n",
    "from functools import partial\n",
    "\n",
    "NUM_MDPs = 100\n",
    "NUM_STATES = 10\n",
    "NUM_ACTIONS = 4\n",
    "\n",
    "def get_transition_matrix(num_states, num_actions, generator = np.random.dirichlet, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a determinstic transition matrix for a given number of states and actions\n",
    "    \n",
    "    Returns:\n",
    "        P: (num_actions, num_states, num_states) array, where P[a, s, s'] is the probability of \n",
    "        transitioning from state s to state s' given action a\n",
    "    \"\"\"\n",
    "    P = np.zeros((num_actions, num_states, num_states)) # (A, S, S') shape\n",
    "    for a in range(num_actions):\n",
    "        for s in range(num_states):\n",
    "            P[a, s, :] = generator(np.ones(num_states))\n",
    "    return P\n",
    "\n",
    "NEAR_ZERO = 0.0001\n",
    "def get_reward_matrix(transitions, sparsity = 0.0, generator = partial(np.random.uniform, -1, 1), **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a reward matrix for a given number of states and actions\n",
    "    [3/16/24 edit: made sparse rewards near-zero to avoid ties, simulate uniformly sampling\n",
    "    the optimal policy]\n",
    "    [3/19/24 test: state-based rewards]\n",
    "    \"\"\"\n",
    "    # in state-based rewards, R[:, :, i] should be a constant matrix\n",
    "    num_sparse = int(sparsity * transitions.shape[2])\n",
    "    rewards = np.array([generator() if i >= num_sparse else np.random.uniform(-1 * NEAR_ZERO, NEAR_ZERO)\n",
    "                        for i in range(transitions.shape[2])])\n",
    "    np.random.shuffle(rewards)\n",
    "    out = np.tile(rewards, (transitions.shape[0], transitions.shape[1], 1))\n",
    "    assert out.shape == transitions.shape\n",
    "    assert all([out[i, j, 0] == rewards[0] for i in range(out.shape[0]) for j in range(out.shape[1])])\n",
    "    return out\n",
    "\n",
    "DISCOUNT = 0.9\n",
    "EPSILON = 0.01 # roughly indicates the \"skill level\" of the agent\n",
    "MAX_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tests(num_mdps = NUM_MDPs, sparsity_levels: np.ndarray = None, mdp_generator = mdpt.mdp.PolicyIterationModified, P_generator = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a bunch of MDPs with different sparsity levels, and return the sparsity levels and the MDPs\n",
    "\n",
    "    Args:\n",
    "        sparsity_levels: a list of sparsity levels to generate MDPs with\n",
    "    Returns:\n",
    "        sparsity_levels: the sparsity levels used to generate the MDPs, in the same order as the MDPs\n",
    "        MDPS: an array of MDPs\n",
    "    \"\"\"\n",
    "    (max_iter, epsilon) = (kwargs['max_iter'], kwargs['epsilon']) if 'max_iter' in kwargs and 'epsilon' in kwargs else (MAX_ITER, EPSILON)\n",
    "    sparsity_levels = sparsity_levels if sparsity_levels is not None else np.arange(num_mdps) / num_mdps\n",
    "    sparsity_copy = sparsity_levels.copy() # defensive copy\n",
    "    np.random.shuffle(sparsity_copy)\n",
    "    transitions = np.array([get_transition_matrix(NUM_STATES, NUM_ACTIONS, **kwargs) if P_generator is None else P_generator(NUM_STATES, NUM_ACTIONS, **kwargs) for i in range(num_mdps)])\n",
    "    \n",
    "    MDPS = np.array([mdp_generator(\n",
    "        transitions[i], \n",
    "        get_reward_matrix(transitions[i], sparsity_copy[i], **kwargs), \n",
    "        DISCOUNT, max_iter = max_iter) \n",
    "        for i in range(num_mdps)\n",
    "    ])\n",
    "    for mdp in MDPS:\n",
    "        if mdp_generator == mdpt.mdp.ValueIteration:\n",
    "            mdp.epsilon = epsilon\n",
    "    return sparsity_copy, MDPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a transition function with various settings for properties (e.g. deterministic, sparse, fixed) and train a classifier to predict P(URS | $\\pi = \\pi_0$) and P(USS | $\\pi = \\pi_0$) (baseline probability = 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs (with baseline/zero sparsity), solve some of them, \n",
    "# generate random policy for others\n",
    "\n",
    "def transition_function_sparse_loops(states, actions, fixed = False, **kwargs):\n",
    "    \"\"\"\n",
    "    Sparse transition function with guaranteed loops\n",
    "    TODO: possibly implement terminal states\n",
    "    \"\"\"\n",
    "    # print(fixed)\n",
    "    rng = np.random.default_rng(seed = 0) if fixed else None\n",
    "    transitions = np.zeros((actions, states, states))\n",
    "    for state in range(states):\n",
    "        self_loop = np.random.randint(0, actions) if not fixed else rng.integers(0, actions)\n",
    "        assert 0 <= self_loop < actions\n",
    "        for action in range(actions):\n",
    "            if action == self_loop:\n",
    "                for next_state in range(states):\n",
    "                    transitions[action, state, next_state] = 1 if next_state == state else 0\n",
    "            else: # sparse randomness\n",
    "                transitions[action, state, :] = np.zeros(states)\n",
    "                transitions[action, state, np.random.randint(states) if not fixed else rng.integers(0, states)] = 1\n",
    "    return transitions\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "#sparsity_levels = np.zeros(NUM_MDPs)\n",
    "# URS would be np.zeros(NUM_MDPs)\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, NUM_MDPs // 2, replace = False) # The indices of the MDPs with random policies\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "MDPS = generate_tests(NUM_MDPs, sparsity_levels = sparsity_levels,\n",
    "                      P_generator = transition_function_sparse_loops, fixed = fixed)[1]\n",
    "# print(np.ndim(MDPS[0].R))\n",
    "# Problem with _bounditer in ValueIteration happening when upper uniform bound is too high/sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "for i in random_pol_indices:\n",
    "    MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([MDPS[1].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)])\n",
    "assert not fixed or np.all([np.all([MDPS[i].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)]) for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 1 1 2 2 1 2 3]\n",
      " [2 3 2 3 0 0 1 0 3 2]\n",
      " [3 1 1 0 0 1 2 1 0 2]\n",
      " [2 3 1 1 0 0 3 1 3 2]\n",
      " [2 3 2 0 2 0 0 2 3 3]\n",
      " [3 1 3 2 0 3 0 1 3 2]\n",
      " [2 3 3 3 1 0 0 2 3 3]\n",
      " [1 2 3 2 2 1 0 2 0 3]\n",
      " [0 1 0 0 3 3 3 0 1 3]\n",
      " [1 1 3 2 2 1 0 0 3 0]] [1 1 1 1 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(policies[0:10], random_or_rr[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "\n",
    "def regression(X, y, test_size = 0.2, regression = LinearRegression):\n",
    "    \"\"\"\n",
    "    Trains a linear regression model on the given data, and returns the model and test data\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model = regression().fit(X_train, y_train)\n",
    "    return model, model.predict_proba(X_test), y_test\n",
    "\n",
    "def neural_network(X, y, test_size = 0.2, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the given data, and returns the model and the mean squared error\n",
    "    \"\"\"\n",
    "    def build_model():\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation = 'relu', input_shape = [X.shape[1]]),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(64, activation = 'relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    model = build_model()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mae'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model.fit(X_train, y_train, epochs = 100, validation_split = 0.2, verbose = 1, \n",
    "              callbacks = [keras.callbacks.EarlyStopping(patience = 3)])\n",
    "    return model, model.predict(X_test), y_test\n",
    "\n",
    "def find_loop_dist_and_length(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Computes the distance to the loop and the length of the loop for a given policy and initial state\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "    \n",
    "    #distance to loop = visited_states[current_state]; loop length = step - visited_states[current_state]\n",
    "    return visited_states[current_state], step - visited_states[current_state]\n",
    "\n",
    "def takes_self_loop(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\" \n",
    "    Returns 1 if the policy takes a self loop, 0 otherwise\n",
    "    \"\"\"\n",
    "    return int(transitions[policy[initial_state]][initial_state][initial_state] > 0.5)\n",
    "\n",
    "def num_out_arrows(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Returns the sum of outgoing arrows for each state that the policy visits from the \n",
    "    initial state before reaching a loop\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "    out_arrows = 0\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "        out_arrows += np.count_nonzero(transitions[policy[current_state]][current_state])\n",
    "    return out_arrows\n",
    "\n",
    "### Generate features\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "# Drop first to avoid multicollinearity, large coefficients\n",
    "# encoder.fit(np.arange(NUM_ACTIONS))\n",
    "# print(encoder.categories_)\n",
    "\n",
    "### Train the model\n",
    "policies_encoded = encoder.fit_transform(policies)\n",
    "features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                      for i in range(NUM_MDPs)])\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES) for x in range(2)] \n",
    "                         for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-entropy loss: 0.3839268627340634\n",
      "Accuracy: 0.838\n",
      "Baseline log loss: 0.6931471805599454\n",
      "Model coefficients, intercept: [[ 8.77117677e-01  5.97399302e-01  5.36527381e-01 -1.57155722e-01\n",
      "  -3.13771464e-01 -3.68876747e-01 -9.91596850e-02  7.74596789e-01\n",
      "   5.18842667e-01  4.57674811e-01  3.99232828e-02 -1.94058175e-01\n",
      "  -5.96285120e-02 -1.16748556e-01 -2.91854502e-01  9.12858193e-01\n",
      "   6.98311356e-01  4.28009907e-01  2.88274416e-01 -9.64641497e-02\n",
      "  -5.32470137e-01 -5.88819685e-01  9.54287034e-01  6.36783718e-01\n",
      "   5.80259259e-01  3.63533961e-01 -1.30968830e-01 -2.97160678e-01\n",
      "  -1.05797177e+00 -9.11972553e-02  9.98609083e-01  7.22510069e-01\n",
      "   5.24227566e-01  4.32344590e-01  1.93692700e-01 -5.08878545e-01\n",
      "  -6.51883402e-01 -6.45729502e-01  8.59650949e-01  7.14778097e-01\n",
      "   4.86082912e-01  2.83065428e-01 -3.30955107e-01 -1.07482675e-01\n",
      "  -6.85374886e-01 -1.51168788e-01  7.81761959e-01  5.55213634e-01\n",
      "   4.82290341e-01  8.22334761e-02  2.54659516e-01 -2.25410045e-01\n",
      "  -4.18300184e-01 -6.97447585e-04 -2.25202970e-01  7.57875508e-01\n",
      "   5.69153413e-01  3.33304278e-01 -9.33644219e-02  1.58841102e-01\n",
      "  -2.02027335e-01 -3.35070534e-01  7.68102044e-01  5.12132247e-01\n",
      "   3.40448928e-01  3.57119699e-02 -2.87730601e-01 -2.18047460e-01\n",
      "   2.54229175e-01 -1.19634964e-01  6.93998517e-01  5.58300499e-01\n",
      "   2.92790171e-01 -6.60390961e-02 -1.21811787e-01  2.51140145e-01\n",
      "  -3.55740740e-01 -5.04598307e-02  0.00000000e+00 -1.06821894e+00\n",
      "  -1.12488600e+00 -1.10583810e+00 -9.53703643e-01 -1.06103076e+00\n",
      "  -1.06473413e+00 -1.28268648e+00 -1.18485021e+00 -1.28134954e+00\n",
      "  -1.19831608e+00]] [-2.22752545]\n",
      "Sample outputs: [(array([0.99481238, 0.00518762]), 0), (array([0.13384658, 0.86615342]), 1), (array([0.201615, 0.798385]), 1), (array([0.50779581, 0.49220419]), 1), (array([0.15739391, 0.84260609]), 1), (array([0.08169016, 0.91830984]), 1), (array([0.52268041, 0.47731959]), 1), (array([0.16993831, 0.83006169]), 0), (array([0.98426039, 0.01573961]), 0), (array([0.80998881, 0.19001119]), 0)]\n"
     ]
    }
   ],
   "source": [
    "# features = np.concatenate((encoder.fit_transform(policies), encoder.fit_transform(loop_lengths),\n",
    "#                            ), axis = 1)\n",
    "# print(loop_lengths[0:10])\n",
    "features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "model, y_pred, y_test = regression(features, random_or_rr, regression = partial(LogisticRegression, max_iter = 1000))\n",
    "print(\"Average cross-entropy loss:\", log_loss(y_test, y_pred, normalize = True))\n",
    "print(\"Accuracy:\", np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])) \n",
    "\n",
    "# if round(y_pred[0]) is 0, then model thinks 1 is more likely; if 1, then 0 is more likely\n",
    "# print(y_pred)\n",
    "print(\"Baseline log loss:\", log_loss(y_test, np.full(y_pred.shape, 0.5), normalize = True))\n",
    "print(\"Model coefficients, intercept:\", model.coef_, model.intercept_)\n",
    "print(\"Sample outputs:\", [(y_pred[i], y_test[i]) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [0 3 3 0 0 2 2 2 2 3] Probability: [0.02551053 0.97448947] Actual: 1\n",
      "Policy: [2 0 1 0 2 0 0 0 2 2] Probability: [0.0220098 0.9779902] Actual: 0\n",
      "Policy: [1 1 0 2 0 0 0 3 0 1] Probability: [0.01892231 0.98107769] Actual: 0\n",
      "Policy: [2 1 3 1 0 0 3 2 2 3] Probability: [0.0147622 0.9852378] Actual: 0\n",
      "Policy: [2 0 2 2 0 2 0 2 0 0] Probability: [0.01390953 0.98609047] Actual: 0\n",
      "Policy: [3 3 1 1 1 0 2 3 0 1] Probability: [9.99694744e-01 3.05256124e-04] Actual: 0\n",
      "Policy: [1 0 1 2 1 0 0 1 1 0] Probability: [9.99654196e-01 3.45803765e-04] Actual: 0\n",
      "Policy: [1 1 3 1 1 1 2 2 0 2] Probability: [9.99648471e-01 3.51528944e-04] Actual: 0\n",
      "Policy: [1 0 1 0 0 2 0 2 1 3] Probability: [9.9964446e-01 3.5554028e-04] Actual: 0\n",
      "Policy: [1 2 3 0 2 1 2 1 0 3] Probability: [9.99622490e-01 3.77509906e-04] Actual: 0\n"
     ]
    }
   ],
   "source": [
    "### Grab the five policies with the highest and lowest probabilities of being random\n",
    "import networkx as nx\n",
    "\n",
    "if fixed:\n",
    "    # Generate a graph of the first MDP\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(NUM_STATES):\n",
    "        G.add_node(i)\n",
    "    enumerated_edges = {}\n",
    "    for i in range(NUM_ACTIONS):\n",
    "        enumerated_edges[i] = []\n",
    "        for j in range(NUM_STATES):\n",
    "            for k in range(NUM_STATES):\n",
    "                if MDPS[0].P[i][j, k] == 1:\n",
    "                    G.add_edge(j, k, action = i)\n",
    "                    enumerated_edges[i].append((j, k))\n",
    "    edge_labels = {(u, v): f\"{d['action']}\" for u, v, d in G.edges(data=True)}\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=20)  # k: Optimal distance between nodes. Increase/decrease to spread nodes out\n",
    "    nx.draw(G, pos = pos, with_labels = True)\n",
    "    nx.draw_networkx_edge_labels(G, pos = pos, edge_labels = edge_labels)\n",
    "    \n",
    "    for i in range(NUM_ACTIONS):\n",
    "        print(f\"Action {i} transitions:\", enumerated_edges[i])\n",
    "\n",
    "highest_probs = np.argsort(y_pred[:, 1])[-5:]\n",
    "lowest_probs = np.argsort(y_pred[:, 1])[:5]\n",
    "#print(\"Highest probabilities:\", [(y_pred[i], y_test[i]) for i in highest_probs])\n",
    "for i in np.concatenate((highest_probs, lowest_probs)):\n",
    "    print(\"Policy:\", policies[i], \"Probability:\", y_pred[i], \"Actual:\", y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On a random deterministic MDP(s), it doesn't seem like URS is identifiable, which is perhaps to be expected as every policy is optimal for some (normalized) reward function\n",
    "    - This also matches our results when looking at the distribution of optimal policies for \"cloud\"-y MDPs\n",
    "- As a control, with MDPs with loops, passing in just the policy (which shouldn't give much information without the related MDP) gives 0.54 accuracy\n",
    "    - Why not 0.50 exactly?\n",
    "    - Similar results with neural network\n",
    "    - This holds true when we use the label predictions for regression (model.predict), as well as the probability prediction (model.predict_proba)\n",
    "- Passing in the policy with the transition function (flattened) gives 0.53 accuracy, even with the NN\n",
    "    - Would likely need a graph neural network to train deep enough \"circuits\" to use the data of the whole transition function effectively\n",
    "- Distance to loop correlates somewhat well with P(URS) (~0.66-0.68 accuracy, 0.61-0.63 log loss on a diverse dataset of sparse transition functions), length of loop not as well (~0.56 accuracy, 0.687 log loss)\n",
    "    - Putting them together doesn't give improvement (~0.67-0.71 accuracy, 0.57-0.62 log loss)\n",
    "    - Intuitively, the length of the loop an optimal policy takes is its “goal complexity”; distance to loop = “agency” \n",
    "- Setting $k \\in U[1, N/2]$ gives:\n",
    "    - 0.56 accuracy, 0.688 log loss with length of loop; 0.66-0.672 accuracy, 0.61 log loss with distance to loop\n",
    "    - Setting the upper bound of $k$ too high results in some weird MDP package errors, I suspect because sparsity is too high\n",
    "    - This matches the distribution results we found in reward_function.ipynb, as sparsity didn't seem to \"matter\" until around ~0.9 given (S, A) = (10, 4)\n",
    "- $k \\in U[1, N]$ gives similar results\n",
    "    - (Note that this was run with PolicyIterationModified instead of ValueIteration with the same settings, which I don't expect to change any of the results, but I might be wrong)\n",
    "    - 0.72-0.74 accuracy with policy, distance to loop, and length of loop\n",
    "- Calculating whether the policy enters a self loop or not for each state $s$ gives 0.80 accuracy, 0.43 log loss!\n",
    "    - With policy and distance to loop included, ~0.82-0.84 accuracy, 0.38-0.40 log loss\n",
    "    - Similar results with neural network\n",
    "    - The logistic coefficients are all negative, lending evidence to the claim that a policy that takes more self-loops is *less* likely to be sampled via URS or USS\n",
    "        - 0.9999 chance of being from UPS if the policy always takes self-loops; 0.95 chance of being from URS/USS if it never takes self-loops\n",
    "- Calculating out-arrows also gives ~0.80 accuracy, 0.44 log loss\n",
    "    - Combining with self-loops doesn't give much\n",
    "    - Coefficients are positive --> a policy that reaches more out-arrows is more likely to be sampled via URS or USS\n",
    "- P(USS) / P(URS) is really difficult (basically 0.5)\n",
    "- Graph results (see plt plot below) fits for P(USS) given uniform k, P(URS)\n",
    "- Apparently when there is only one reward, passing in policy is *more* predictive than LL or O,S (.77 acc, .45 LL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the model's performance\n",
    "### This is the cell that generated the plots in our reports\n",
    "\n",
    "num_runs = 90\n",
    "accuracies = np.zeros((num_runs // 3, 3))\n",
    "log_losses = np.zeros((num_runs // 3, 3))\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "# sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "# sparsity_levels = np.random.uniform(1.0 - 1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs) #high sparsity\n",
    "sparsity_levels = np.zeros(NUM_MDPs) #no sparsity\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, NUM_MDPs // 2, replace = False) \n",
    "# The indices of the MDPs with random policies (or random dense rewards)\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "\n",
    "# to measure P(USS) / P(URS), \n",
    "# let sparsity_levels = [sparsity_levels[i] if i in random_pol_set else 0 for i in range(NUM_MDPs)]\n",
    "MDPS = generate_tests(NUM_MDPs, sparsity_levels = sparsity_levels,\n",
    "                    P_generator = transition_function_sparse_loops, fixed = fixed)[1]\n",
    "\n",
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "for i in random_pol_indices: #comment out when measuring P(USS) / P(URS)\n",
    "    MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR\n",
    "\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES)\n",
    "                           for x in range(2)] for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "\n",
    "for n in range(num_runs):\n",
    "    ### Train the model\n",
    "    policies_encoded = encoder.fit_transform(policies)\n",
    "    features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                        for i in range(NUM_MDPs)])\n",
    "\n",
    "    if n % 3 == 2:\n",
    "        features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "    elif n % 3 == 1:\n",
    "        features = encoder.fit_transform(loop_lengths)\n",
    "    model, y_pred, y_test = regression(features, random_or_rr, regression=partial(LogisticRegression, max_iter=MAX_ITER))\n",
    "    accuracy = np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])\n",
    "    log_loss_value = log_loss(y_test, y_pred, normalize=True)\n",
    "    accuracies[n // 3][n % 3] = accuracy\n",
    "    log_losses[n // 3][n % 3] = log_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(np.array([x for pair in zip(accuracies.T, log_losses.T) for x in pair]).T, labels=\n",
    "            ['Accuracy (P)', 'Log Loss (P)', 'Accuracy (LL)', 'Log Loss (LL)', 'Accuracy (O,S)', 'Log Loss (O,S)'])\n",
    "plt.title('Regression Performances with Different Features')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0.3, 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "M = get_reward_matrix(transition_function_sparse_loops(10, 4), 1.0 - 1.0/NUM_ACTIONS/NUM_STATES**2/2)\n",
    "print(sum([abs(m) > NEAR_ZERO for m in M.flatten()]))\n",
    "print(np.count_nonzero(M))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
