{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: measure how correlated certain features of the policy $\\pi_0$ are to the value $P(URS | \\pi=\\pi_0)$, where $URS$ indicates that the policy was optimized for a random reward function $R \\in U[-1,1]^{|T|}$ (where $|T|$ is the number of transitions with non-zero probability). For simplicity's sake, we assume that it was either optimized for some $R$ or generated uniformly randomly from the set of all policies, with a 50% chance of each scenario. We also assume that the reward is generated i.i.d. via $R(s, a, s') \\sim N(0, 1)$.\n",
    "\n",
    "We can also analyze $P(USS | \\pi = \\pi_0)$ where $USS$ consists of sampling a sparsity factor $k \\in [1, |T|]$, then zeroing out $k$ values from a randomly sampled $R$ as before.\n",
    "\n",
    "***For outside observers: see the bottom two cells for how the graphs in our report were generated***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox as mdpt, numpy as np\n",
    "import mdptoolbox.example\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs with different parameters, sparsity\n",
    "from functools import partial\n",
    "\n",
    "NUM_MDPs = 100\n",
    "NUM_STATES = 10\n",
    "NUM_ACTIONS = 4\n",
    "\n",
    "def get_transition_matrix(num_states, num_actions, generator = np.random.dirichlet, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a determinstic transition matrix for a given number of states and actions\n",
    "    \n",
    "    Returns:\n",
    "        P: (num_actions, num_states, num_states) array, where P[a, s, s'] is the probability of \n",
    "        transitioning from state s to state s' given action a\n",
    "    \"\"\"\n",
    "    P = np.zeros((num_actions, num_states, num_states)) # (A, S, S') shape\n",
    "    for a in range(num_actions):\n",
    "        for s in range(num_states):\n",
    "            P[a, s, :] = generator(np.ones(num_states))\n",
    "    return P\n",
    "\n",
    "NEAR_ZERO = 0.0001\n",
    "def get_reward_matrix(transitions, sparsity = 0.0, generator = partial(np.random.uniform, -1, 1), **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a reward matrix for a given number of states and actions\n",
    "    [3/16/24 edit: made sparse rewards near-zero to avoid ties, simulate uniformly sampling\n",
    "    the optimal policy]\n",
    "    \"\"\"\n",
    "    num_pos_transitions = np.count_nonzero(transitions)\n",
    "    num_sparse_rewards = max(1, int(sparsity * num_pos_transitions))\n",
    "    rewards = np.array([(np.random.uniform(-1.0 * NEAR_ZERO, NEAR_ZERO) \n",
    "                         if i < num_sparse_rewards else generator()) for i in range(num_pos_transitions)])\n",
    "    np.random.shuffle(rewards) # create a random permutation of the rewards\n",
    "    # num_pos_transitions number of rewards, with num_sparse_rewards number of zeros\n",
    "    out = np.zeros(transitions.shape)\n",
    "    i = 0\n",
    "    for a, s, s_prime in np.argwhere(transitions):\n",
    "        out[a, s, s_prime] = rewards[i]\n",
    "        i += 1\n",
    "    # assert (np.abs(out) < np.full(out.shape, NEAR_ZERO)).sum() == num_pos_transitions - num_sparse_rewards\n",
    "    return out\n",
    "\n",
    "DISCOUNT = 0.9\n",
    "EPSILON = 0.01 # roughly indicates the \"skill level\" of the agent\n",
    "MAX_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tests(num_mdps = NUM_MDPs, sparsity_levels: np.ndarray = None, mdp_generator = mdpt.mdp.PolicyIterationModified, P_generator = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a bunch of MDPs with different sparsity levels, and return the sparsity levels and the MDPs\n",
    "\n",
    "    Args:\n",
    "        sparsity_levels: a list of sparsity levels to generate MDPs with\n",
    "    Returns:\n",
    "        sparsity_levels: the sparsity levels used to generate the MDPs, in the same order as the MDPs\n",
    "        MDPS: an array of MDPs\n",
    "    \"\"\"\n",
    "    (max_iter, epsilon) = (kwargs['max_iter'], kwargs['epsilon']) if 'max_iter' in kwargs and 'epsilon' in kwargs else (MAX_ITER, EPSILON)\n",
    "    sparsity_levels = sparsity_levels if sparsity_levels is not None else np.arange(num_mdps) / num_mdps\n",
    "    sparsity_copy = sparsity_levels.copy() # defensive copy\n",
    "    np.random.shuffle(sparsity_copy)\n",
    "    transitions = np.array([get_transition_matrix(NUM_STATES, NUM_ACTIONS, **kwargs) if P_generator is None else P_generator(NUM_STATES, NUM_ACTIONS, **kwargs) for i in range(num_mdps)])\n",
    "    \n",
    "    MDPS = np.array([mdp_generator(\n",
    "        transitions[i], \n",
    "        get_reward_matrix(transitions[i], sparsity_copy[i], **kwargs), \n",
    "        DISCOUNT, max_iter = max_iter) \n",
    "        for i in range(num_mdps)\n",
    "    ])\n",
    "    for mdp in MDPS:\n",
    "        if mdp_generator == mdpt.mdp.ValueIteration:\n",
    "            mdp.epsilon = epsilon\n",
    "    return sparsity_copy, MDPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a transition function with various settings for properties (e.g. deterministic, sparse, fixed) and train a classifier to predict P(URS | $\\pi = \\pi_0$) and P(USS | $\\pi = \\pi_0$) (baseline probability = 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs (with baseline/zero sparsity), solve some of them, \n",
    "# generate random policy for others\n",
    "\n",
    "def transition_function_sparse_loops(states, actions, fixed = False, **kwargs):\n",
    "    \"\"\"\n",
    "    Sparse transition function with guaranteed loops\n",
    "    TODO: possibly implement terminal states\n",
    "    \"\"\"\n",
    "    # print(fixed)\n",
    "    rng = np.random.default_rng(seed = 0) if fixed else None\n",
    "    transitions = np.zeros((actions, states, states))\n",
    "    for state in range(states):\n",
    "        self_loop = np.random.randint(0, actions) if not fixed else rng.integers(0, actions)\n",
    "        for action in range(actions):\n",
    "            if action == self_loop:\n",
    "                for next_state in range(states):\n",
    "                    transitions[action, state, next_state] = 1 if next_state == state else 0\n",
    "            else: # sparse randomness\n",
    "                transitions[action, state, :] = np.zeros(states)\n",
    "                transitions[action, state, np.random.randint(states) if not fixed else rng.integers(0, states)] = 1\n",
    "    return transitions\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "#sparsity_levels = np.zeros(NUM_MDPs)\n",
    "# URS would be np.zeros(NUM_MDPs)\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, NUM_MDPs // 2, replace = False) # The indices of the MDPs with random policies\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "MDPS = generate_tests(NUM_MDPs, sparsity_levels = sparsity_levels,\n",
    "                      P_generator = transition_function_sparse_loops, fixed = fixed)[1]\n",
    "# print(np.ndim(MDPS[0].R))\n",
    "# Problem with _bounditer in ValueIteration happening when upper uniform bound is too high/sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "for i in random_pol_indices:\n",
    "    MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([MDPS[1].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)])\n",
    "assert not fixed or np.all([np.all([MDPS[i].P[j] == MDPS[0].P[j] for j in range(NUM_ACTIONS)]) for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 2 1 3 3 3 2 2 0]\n",
      " [1 3 3 2 1 3 2 0 3 1]\n",
      " [3 3 1 3 1 3 1 3 1 1]\n",
      " [3 2 3 1 1 2 0 3 3 1]\n",
      " [3 3 1 2 0 0 3 1 0 2]\n",
      " [2 0 0 1 1 2 1 2 2 1]\n",
      " [3 3 1 3 0 1 0 0 3 1]\n",
      " [2 2 3 3 0 0 1 0 0 2]\n",
      " [3 1 1 3 2 1 0 1 2 1]\n",
      " [2 3 3 1 3 0 3 0 2 2]] [0 1 1 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(policies[0:10], random_or_rr[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "\n",
    "def regression(X, y, test_size = 0.2, regression = LinearRegression):\n",
    "    \"\"\"\n",
    "    Trains a linear regression model on the given data, and returns the model and test data\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model = regression().fit(X_train, y_train)\n",
    "    return model, model.predict_proba(X_test), y_test\n",
    "\n",
    "def neural_network(X, y, test_size = 0.2, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the given data, and returns the model and the mean squared error\n",
    "    \"\"\"\n",
    "    def build_model():\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation = 'relu', input_shape = [X.shape[1]]),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(64, activation = 'relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    model = build_model()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mae'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    model.fit(X_train, y_train, epochs = 100, validation_split = 0.2, verbose = 1, \n",
    "              callbacks = [keras.callbacks.EarlyStopping(patience = 3)])\n",
    "    return model, model.predict(X_test), y_test\n",
    "\n",
    "def find_loop_dist_and_length(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Computes the distance to the loop and the length of the loop for a given policy and initial state\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "    \n",
    "    #distance to loop = visited_states[current_state]; loop length = step - visited_states[current_state]\n",
    "    return visited_states[current_state], step - visited_states[current_state]\n",
    "\n",
    "def takes_self_loop(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\" \n",
    "    Returns 1 if the policy takes a self loop, 0 otherwise\n",
    "    \"\"\"\n",
    "    return int(transitions[policy[initial_state]][initial_state][initial_state] > 0.5)\n",
    "\n",
    "def num_out_arrows(transitions, policy: np.ndarray, initial_state):\n",
    "    \"\"\"\n",
    "    Returns the sum of outgoing arrows for each state that the policy visits from the \n",
    "    initial state before reaching a loop\n",
    "    \"\"\"\n",
    "    visited_states = {}  # Using a dict for quicker lookups\n",
    "    current_state = initial_state\n",
    "    step = 0  # Track the number of steps taken to find the loop length directly\n",
    "    out_arrows = 0\n",
    "    while current_state not in visited_states:\n",
    "        visited_states[current_state] = step\n",
    "        # Simulate a transition\n",
    "        current_state = np.random.choice(np.arange(len(policy)), 1, \n",
    "                                         p = transitions[policy[current_state]][current_state]).item()\n",
    "        step += 1\n",
    "        out_arrows += np.count_nonzero(transitions[policy[current_state]][current_state])\n",
    "    return out_arrows\n",
    "\n",
    "### Generate features\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "# Drop first to avoid multicollinearity, large coefficients\n",
    "# encoder.fit(np.arange(NUM_ACTIONS))\n",
    "# print(encoder.categories_)\n",
    "\n",
    "### Train the model\n",
    "policies_encoded = encoder.fit_transform(policies)\n",
    "features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                      for i in range(NUM_MDPs)])\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES) for x in range(2)] \n",
    "                         for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-entropy loss: 0.4269756066720329\n",
      "Accuracy: 0.814\n",
      "Baseline log loss: 0.6931471805599454\n",
      "Model coefficients, intercept: [[ 5.47574906e-01  5.53963621e-01  2.78333594e-01  1.81025887e-01\n",
      "   2.69665288e-01 -4.49369397e-02 -1.21884879e-01 -5.80436302e-01\n",
      "   2.34826838e-01  2.21786282e-01  1.62782927e-01 -5.89652465e-02\n",
      "   2.93042549e-01  2.30272543e-01  2.03931569e-01  1.05292979e-01\n",
      "   2.76147839e-02  2.15242024e-01  3.64727645e-01  2.45235466e-01\n",
      "   1.62194151e-01  3.28136658e-01 -1.72239820e-01 -4.18648799e-01\n",
      "   5.70352554e-01  2.92159825e-01  3.94763624e-01  2.38569756e-01\n",
      "   1.87960128e-01  1.57907386e-02 -5.20666500e-01  3.70576912e-01\n",
      "   2.71277736e-01  3.61446133e-01  2.10201709e-01  2.08989954e-01\n",
      "  -8.61049266e-02 -6.03628070e-02  6.52166244e-02 -2.12149735e-01\n",
      "   8.97847021e-01  2.88926634e-01  3.05046909e-01  4.12135623e-01\n",
      "   1.66868828e-01  6.30199977e-02 -2.64522512e-01  1.74078075e-04\n",
      "   5.88143758e-01 -2.50185273e-01  4.99945337e-01  3.71534015e-01\n",
      "   4.61318318e-01  1.96211531e-01  1.51764823e-01  2.52381950e-01\n",
      "  -3.95219119e-01 -5.00235246e-01  1.77549211e-01  1.94036407e-01\n",
      "   1.90518266e-01 -5.76034908e-02 -7.60778335e-02 -1.32357578e-01\n",
      "   4.32227430e-01  5.53075271e-01  1.10089976e-01  3.15872474e-01\n",
      "   3.94256934e-01  2.63127720e-01  7.78140842e-02  1.60606310e-01\n",
      "  -2.20237195e-01  4.20865345e-01 -1.07618326e-01  3.00817465e-01\n",
      "   2.99019567e-01  2.16778319e-01 -7.55107981e-02  6.79409735e-02\n",
      "  -2.76619391e-01 -2.46229444e-01  1.09645046e+00 -1.08154088e+00\n",
      "  -1.41882093e+00 -1.29323558e+00 -1.24866793e+00 -1.38331968e+00\n",
      "  -1.30784375e+00 -1.03593732e+00 -1.38969336e+00 -1.30292305e+00\n",
      "  -1.38088285e+00]] [0.52713536]\n",
      "Sample outputs: [(array([0.21414991, 0.78585009]), 1), (array([0.34421628, 0.65578372]), 1), (array([0.32328034, 0.67671966]), 0), (array([0.99736444, 0.00263556]), 0), (array([0.13380475, 0.86619525]), 1), (array([0.50843446, 0.49156554]), 1), (array([0.25115451, 0.74884549]), 1), (array([0.93473483, 0.06526517]), 0), (array([0.11964456, 0.88035544]), 1), (array([0.73604747, 0.26395253]), 0)]\n"
     ]
    }
   ],
   "source": [
    "# features = np.concatenate((encoder.fit_transform(policies), encoder.fit_transform(loop_lengths),\n",
    "#                            ), axis = 1)\n",
    "# print(loop_lengths[0:10])\n",
    "features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "model, y_pred, y_test = regression(features, random_or_rr, regression = partial(LogisticRegression, max_iter = 1000))\n",
    "print(\"Average cross-entropy loss:\", log_loss(y_test, y_pred, normalize = True))\n",
    "print(\"Accuracy:\", np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])) \n",
    "\n",
    "# if round(y_pred[0]) is 0, then model thinks 1 is more likely; if 1, then 0 is more likely\n",
    "# print(y_pred)\n",
    "print(\"Baseline log loss:\", log_loss(y_test, np.full(y_pred.shape, 0.5), normalize = True))\n",
    "print(\"Model coefficients, intercept:\", model.coef_, model.intercept_)\n",
    "print(\"Sample outputs:\", [(y_pred[i], y_test[i]) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [1 1 0 3 1 3 1 1 2 1] Probability: [0.02089572 0.97910428] Actual: 1\n",
      "Policy: [2 3 0 1 1 2 2 2 0 1] Probability: [0.01913204 0.98086796] Actual: 1\n",
      "Policy: [0 0 1 0 0 0 1 0 0 3] Probability: [0.01861456 0.98138544] Actual: 1\n",
      "Policy: [0 0 1 3 3 1 0 1 0 1] Probability: [0.01847028 0.98152972] Actual: 0\n",
      "Policy: [3 2 0 2 0 0 1 0 2 1] Probability: [0.01792243 0.98207757] Actual: 1\n",
      "Policy: [3 0 2 3 2 0 2 2 0 0] Probability: [9.99977386e-01 2.26136454e-05] Actual: 0\n",
      "Policy: [1 3 3 2 3 3 2 1 3 2] Probability: [9.99898075e-01 1.01924891e-04] Actual: 0\n",
      "Policy: [2 0 0 0 1 3 1 0 3 1] Probability: [9.99865970e-01 1.34029527e-04] Actual: 0\n",
      "Policy: [0 1 1 2 0 0 2 1 2 3] Probability: [9.99507653e-01 4.92346990e-04] Actual: 0\n",
      "Policy: [1 2 2 0 0 2 1 1 3 2] Probability: [9.99461934e-01 5.38066115e-04] Actual: 0\n"
     ]
    }
   ],
   "source": [
    "### Grab the five policies with the highest and lowest probabilities of being random\n",
    "import networkx as nx\n",
    "\n",
    "if fixed:\n",
    "    # Generate a graph of the first MDP\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(NUM_STATES):\n",
    "        G.add_node(i)\n",
    "    enumerated_edges = {}\n",
    "    for i in range(NUM_ACTIONS):\n",
    "        enumerated_edges[i] = []\n",
    "        for j in range(NUM_STATES):\n",
    "            for k in range(NUM_STATES):\n",
    "                if MDPS[0].P[i][j, k] == 1:\n",
    "                    G.add_edge(j, k, action = i)\n",
    "                    enumerated_edges[i].append((j, k))\n",
    "    edge_labels = {(u, v): f\"{d['action']}\" for u, v, d in G.edges(data=True)}\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=20)  # k: Optimal distance between nodes. Increase/decrease to spread nodes out\n",
    "    nx.draw(G, pos = pos, with_labels = True)\n",
    "    nx.draw_networkx_edge_labels(G, pos = pos, edge_labels = edge_labels)\n",
    "    \n",
    "    for i in range(NUM_ACTIONS):\n",
    "        print(f\"Action {i} transitions:\", enumerated_edges[i])\n",
    "\n",
    "highest_probs = np.argsort(y_pred[:, 1])[-5:]\n",
    "lowest_probs = np.argsort(y_pred[:, 1])[:5]\n",
    "#print(\"Highest probabilities:\", [(y_pred[i], y_test[i]) for i in highest_probs])\n",
    "for i in np.concatenate((highest_probs, lowest_probs)):\n",
    "    print(\"Policy:\", policies[i], \"Probability:\", y_pred[i], \"Actual:\", y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On a random deterministic MDP(s), it doesn't seem like URS is identifiable, which is perhaps to be expected as every policy is optimal for some (normalized) reward function\n",
    "    - This also matches our results when looking at the distribution of optimal policies for \"cloud\"-y MDPs\n",
    "- As a control, with MDPs with loops, passing in just the policy (which shouldn't give much information without the related MDP) gives 0.54 accuracy\n",
    "    - Why not 0.50 exactly?\n",
    "    - Similar results with neural network\n",
    "    - This holds true when we use the label predictions for regression (model.predict), as well as the probability prediction (model.predict_proba)\n",
    "- Passing in the policy with the transition function (flattened) gives 0.53 accuracy, even with the NN\n",
    "    - Would likely need a graph neural network to train deep enough \"circuits\" to use the data of the whole transition function effectively\n",
    "- Distance to loop correlates somewhat well with P(URS) (~0.66-0.68 accuracy, 0.61-0.63 log loss on a diverse dataset of sparse transition functions), length of loop not as well (~0.56 accuracy, 0.687 log loss)\n",
    "    - Putting them together doesn't give improvement (~0.67-0.71 accuracy, 0.57-0.62 log loss)\n",
    "    - Intuitively, the length of the loop an optimal policy takes is its “goal complexity”; distance to loop = “agency” \n",
    "- Setting $k \\in U[1, N/2]$ gives:\n",
    "    - 0.56 accuracy, 0.688 log loss with length of loop; 0.66-0.672 accuracy, 0.61 log loss with distance to loop\n",
    "    - Setting the upper bound of $k$ too high results in some weird MDP package errors, I suspect because sparsity is too high\n",
    "    - This matches the distribution results we found in reward_function.ipynb, as sparsity didn't seem to \"matter\" until around ~0.9 given (S, A) = (10, 4)\n",
    "- $k \\in U[1, N]$ gives similar results\n",
    "    - (Note that this was run with PolicyIterationModified instead of ValueIteration with the same settings, which I don't expect to change any of the results, but I might be wrong)\n",
    "    - 0.72-0.74 accuracy with policy, distance to loop, and length of loop\n",
    "- Calculating whether the policy enters a self loop or not for each state $s$ gives 0.80 accuracy, 0.43 log loss!\n",
    "    - With policy and distance to loop included, ~0.82-0.84 accuracy, 0.38-0.40 log loss\n",
    "    - Similar results with neural network\n",
    "    - The logistic coefficients are all negative, lending evidence to the claim that a policy that takes more self-loops is *less* likely to be sampled via URS or USS\n",
    "        - 0.9999 chance of being from UPS if the policy always takes self-loops; 0.95 chance of being from URS/USS if it never takes self-loops\n",
    "- Calculating out-arrows also gives ~0.80 accuracy, 0.44 log loss\n",
    "    - Combining with self-loops doesn't give much\n",
    "    - Coefficients are positive --> a policy that reaches more out-arrows is more likely to be sampled via URS or USS\n",
    "- P(USS) / P(URS) is really difficult (basically 0.5)\n",
    "- Graph results (see plt plot below) fits for P(USS) given uniform k, P(URS)\n",
    "- Apparently when there is only one reward, passing in policy is *more* predictive than LL or O,S (.77 acc, .45 LL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the model's performance\n",
    "### This is the cell that generated the plots in our reports\n",
    "\n",
    "num_runs = 90\n",
    "accuracies = np.zeros((num_runs // 3, 3))\n",
    "log_losses = np.zeros((num_runs // 3, 3))\n",
    "\n",
    "NUM_MDPs = 10000\n",
    "fixed = False\n",
    "#print(np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1, NUM_MDPs))\n",
    "sparsity_levels = np.random.uniform(1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs)\n",
    "# sparsity_levels = np.random.uniform(1.0 - 1.0/NUM_ACTIONS/NUM_STATES**2, 1.0, NUM_MDPs) #high sparsity\n",
    "# sparsity_levels = np.zeros(NUM_MDPs) #no sparsity\n",
    "\n",
    "random_pol_indices = np.random.choice(NUM_MDPs, NUM_MDPs // 2, replace = False) \n",
    "# The indices of the MDPs with random policies (or random dense rewards)\n",
    "random_pol_set = set(random_pol_indices)\n",
    "# i not in random_pol_set = random_or_rr[i] == 1, sparsity_levels[i] > 0\n",
    "\n",
    "# to measure P(USS) / P(URS), \n",
    "# let sparsity_levels = [sparsity_levels[i] if i in random_pol_set else 0 for i in range(NUM_MDPs)]\n",
    "MDPS = generate_tests(\n",
    "    NUM_MDPs, sparsity_levels = [sparsity_levels[i] if i in random_pol_set else 0 for i in range(NUM_MDPs)],\n",
    "    P_generator = transition_function_sparse_loops, fixed = fixed\n",
    ")[1]\n",
    "\n",
    "# print(random_pol_indices)\n",
    "for i in range(NUM_MDPs): # 50% RR, 50% random\n",
    "    MDPS[i].run()\n",
    "# for i in random_pol_indices: #comment out when measuring P(USS) / P(URS)\n",
    "#     MDPS[i].policy = np.random.randint(NUM_ACTIONS, size = NUM_STATES)\n",
    "policies = np.array([mdp.policy for mdp in MDPS])\n",
    "# print(policies.shape)\n",
    "random_or_rr = np.array([0 if i in random_pol_set else 1 for i in range(NUM_MDPs)])\n",
    "# 0 if random, 1 if generated from RR\n",
    "\n",
    "encoder = OneHotEncoder(categories = 'auto', sparse_output = False, drop = 'first')\n",
    "\n",
    "# features = encoder.fit_transform(policies)\n",
    "loop_lengths = np.array([[find_loop_dist_and_length(MDPS[i].P, policies[i], policies[i][j])[x] for j in range(NUM_STATES)\n",
    "                           for x in range(2)] for i in range(NUM_MDPs)])\n",
    "self_loops = np.array([[takes_self_loop(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "# features = np.concatenate((features, encoder.fit_transform(loop_lengths)), axis = 1)\n",
    "out_arrows = np.array([[num_out_arrows(MDPS[i].P, policies[i], j) for j in range(NUM_STATES)] for i in range(NUM_MDPs)])\n",
    "\n",
    "for n in range(num_runs):\n",
    "    ### Train the model\n",
    "    policies_encoded = encoder.fit_transform(policies)\n",
    "    features = np.array([np.concatenate((np.array(MDPS[i].P).flatten(), policies_encoded[i]), axis = 0)\n",
    "                        for i in range(NUM_MDPs)])\n",
    "\n",
    "    if n % 3 == 2:\n",
    "        features = np.concatenate((encoder.fit_transform(out_arrows), self_loops), axis = 1) # for interpretability\n",
    "    elif n % 3 == 1:\n",
    "        features = encoder.fit_transform(loop_lengths)\n",
    "    model, y_pred, y_test = regression(features, random_or_rr, regression=partial(LogisticRegression, max_iter=MAX_ITER))\n",
    "    accuracy = np.mean([np.round(y_pred[i][0]) != y_test[i] for i in range(len(y_pred))])\n",
    "    log_loss_value = log_loss(y_test, y_pred, normalize=True)\n",
    "    accuracies[n // 3][n % 3] = accuracy\n",
    "    log_losses[n // 3][n % 3] = log_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "data = log_losses\n",
    "plt.boxplot(\n",
    "    data,\n",
    "    labels=['Log Loss (P)', 'Log Loss (LL)', 'Log Loss (O,S)']\n",
    ")\n",
    "plt.errorbar(\n",
    "    np.arange(1, 4),\n",
    "    np.mean(data, axis=0),\n",
    "    yerr=np.std(data, axis=0) / np.sqrt(data.shape[0]),\n",
    "    capsize = 5, \n",
    "    label = \"Mean ± 2 SEM\"\n",
    ")\n",
    "baseline = 0.5 if data is accuracies else 0.6931\n",
    "plt.plot(np.arange(1, 4), np.full(data.shape[1], baseline), 'r--', label = \"Baseline\")\n",
    "plt.title('Regression Performances with Different Features')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0.3, 0.9)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "M = get_reward_matrix(transition_function_sparse_loops(10, 4), 1.0 - 1.0/NUM_ACTIONS/NUM_STATES**2/2)\n",
    "print(sum([abs(m) > NEAR_ZERO for m in M.flatten()]))\n",
    "print(np.count_nonzero(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([x for pair in zip(accuracies.T, log_losses.T) for x in pair]).T.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
