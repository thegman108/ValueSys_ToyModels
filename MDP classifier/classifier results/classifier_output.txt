10^5 data points, (S, A) = (10, 4), reward defined over (S, A)

Neural Network (three layers of width 64), MSE test sample size = 1000
Epoch 1/100
2500/2500 [==============================] - 6s 2ms/step - loss: 0.0414 - mae: 0.1639 - val_loss: 0.0343 - val_mae: 0.1530
Epoch 2/100
2500/2500 [==============================] - 6s 2ms/step - loss: 0.0349 - mae: 0.1511 - val_loss: 0.0381 - val_mae: 0.1671
Epoch 3/100
2500/2500 [==============================] - 4s 2ms/step - loss: 0.0339 - mae: 0.1484 - val_loss: 0.0364 - val_mae: 0.1619
Epoch 4/100
2500/2500 [==============================] - 5s 2ms/step - loss: 0.0333 - mae: 0.1466 - val_loss: 0.0354 - val_mae: 0.1569
Mean squared error: 0.03433351376171234
Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...

Linear Regression
Mean squared error: 0.03465722608844792
Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...
Mean absolute error: 0.147748614640625


(As a control, when the input layer of the NN is randomized:)
Epoch 1/100
2500/2500 [==============================] - 7s 2ms/step - loss: 0.0888 - mae: 0.2556 - val_loss: 0.0826 - val_mae: 0.2485
Epoch 2/100
2500/2500 [==============================] - 5s 2ms/step - loss: 0.0843 - mae: 0.2511 - val_loss: 0.0821 - val_mae: 0.2479
Epoch 3/100
2500/2500 [==============================] - 7s 3ms/step - loss: 0.0840 - mae: 0.2508 - val_loss: 0.0828 - val_mae: 0.2486
Epoch 4/100
2500/2500 [==============================] - 10s 4ms/step - loss: 0.0839 - mae: 0.2508 - val_loss: 0.0821 - val_mae: 0.2479
Epoch 5/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0838 - mae: 0.2507 - val_loss: 0.0823 - val_mae: 0.2481
Epoch 6/100
2500/2500 [==============================] - 8s 3ms/step - loss: 0.0838 - mae: 0.2507 - val_loss: 0.0821 - val_mae: 0.2479
Epoch 7/100
2500/2500 [==============================] - 9s 3ms/step - loss: 0.0837 - mae: 0.2506 - val_loss: 0.0821 - val_mae: 0.2479
Epoch 8/100
2500/2500 [==============================] - 7s 3ms/step - loss: 0.0837 - mae: 0.2506 - val_loss: 0.0821 - val_mae: 0.2479
Epoch 9/100
2500/2500 [==============================] - 7s 3ms/step - loss: 0.0837 - mae: 0.2506 - val_loss: 0.0821 - val_mae: 0.2479
Epoch 10/100
2500/2500 [==============================] - 7s 3ms/step - loss: 0.0837 - mae: 0.2506 - val_loss: 0.0821 - val_mae: 0.2479
Mean squared error: 0.08334559122980353
Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...


When given only the optimal policy as input:
Epoch 1/100
2500/2500 [==============================] - 6s 2ms/step - loss: 0.0447 - mae: 0.1675 - val_loss: 0.0316 - val_mae: 0.1427
Epoch 2/100
2500/2500 [==============================] - 4s 1ms/step - loss: 0.0338 - mae: 0.1473 - val_loss: 0.0316 - val_mae: 0.1422
Epoch 3/100
2500/2500 [==============================] - 4s 2ms/step - loss: 0.0331 - mae: 0.1455 - val_loss: 0.0332 - val_mae: 0.1431
Epoch 4/100
2500/2500 [==============================] - 4s 1ms/step - loss: 0.0327 - mae: 0.1443 - val_loss: 0.0310 - val_mae: 0.1404
Epoch 5/100
2500/2500 [==============================] - 4s 2ms/step - loss: 0.0326 - mae: 0.1441 - val_loss: 0.0325 - val_mae: 0.1425
Epoch 6/100
2500/2500 [==============================] - 10s 4ms/step - loss: 0.0324 - mae: 0.1437 - val_loss: 0.0319 - val_mae: 0.1414
Epoch 7/100
2500/2500 [==============================] - 7s 3ms/step - loss: 0.0323 - mae: 0.1435 - val_loss: 0.0319 - val_mae: 0.1404
Mean squared error: 0.030550246489187794
Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...

Linear Regression
Mean squared error: 0.034644988757594135
Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...
Mean absolute error: 0.14728065847843558


When (S, A) = (10, 16), and only policy passed in (runtime = ~8m)
Epoch 1/100
2500/2500 [==============================] - 14s 5ms/step - loss: 0.0716 - mae: 0.2233 - val_loss: 0.0588 - val_mae: 0.1945
Epoch 2/100
2500/2500 [==============================] - 14s 5ms/step - loss: 0.0572 - mae: 0.1994 - val_loss: 0.0536 - val_mae: 0.1890
Epoch 3/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0551 - mae: 0.1947 - val_loss: 0.0561 - val_mae: 0.1876
Epoch 4/100
2500/2500 [==============================] - 13s 5ms/step - loss: 0.0538 - mae: 0.1921 - val_loss: 0.0516 - val_mae: 0.1832
Epoch 5/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0526 - mae: 0.1895 - val_loss: 0.0503 - val_mae: 0.1870
Epoch 6/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0518 - mae: 0.1876 - val_loss: 0.0506 - val_mae: 0.1854
Epoch 7/100
2500/2500 [==============================] - 13s 5ms/step - loss: 0.0513 - mae: 0.1866 - val_loss: 0.0502 - val_mae: 0.1789
Epoch 8/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0511 - mae: 0.1863 - val_loss: 0.0508 - val_mae: 0.1850
Epoch 9/100
2500/2500 [==============================] - 13s 5ms/step - loss: 0.0506 - mae: 0.1852 - val_loss: 0.0491 - val_mae: 0.1797
Epoch 10/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0504 - mae: 0.1847 - val_loss: 0.0497 - val_mae: 0.1818
Epoch 11/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0504 - mae: 0.1847 - val_loss: 0.0487 - val_mae: 0.1811
Epoch 12/100
2500/2500 [==============================] - 13s 5ms/step - loss: 0.0504 - mae: 0.1845 - val_loss: 0.0498 - val_mae: 0.1808
Epoch 13/100
2500/2500 [==============================] - 12s 5ms/step - loss: 0.0502 - mae: 0.1841 - val_loss: 0.0496 - val_mae: 0.1878
Epoch 14/100
2500/2500 [==============================] - 13s 5ms/step - loss: 0.0502 - mae: 0.1842 - val_loss: 0.0488 - val_mae: 0.1814
Mean squared error: 0.049309890374534066, sample size: 1000
Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...

Linear Regression
Mean squared error: 0.06012590289578029
Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...
Mean absolute error: 0.20651512107655748

Weights of linear regression given original experiment setup:
array([ 3.48886787e+09,  3.48886787e+09,  3.48886787e+09,  3.48886787e+09,
        3.48886787e+09,  3.48886787e+09,  3.48886787e+09,  3.48886787e+09,
        3.48886787e+09,  3.48886787e+09, -6.22728255e+10, -6.22728255e+10,
       -6.22728255e+10, -6.22728255e+10, -6.22728255e+10, -6.22728255e+10,
       -6.22728255e+10, -6.22728255e+10, -6.22728255e+10, -6.22728255e+10,
       -1.27669832e+11, -1.27669832e+11, -1.27669832e+11, -1.27669832e+11,
       -1.27669832e+11, -1.27669832e+11, -1.27669832e+11, -1.27669832e+11,
       -1.27669832e+11, -1.27669832e+11, -1.02236399e+11, -1.02236399e+11,
       -1.02236399e+11, -1.02236399e+11, -1.02236399e+11, -1.02236399e+11,
       -1.02236399e+11, -1.02236399e+11, -1.02236399e+11, -1.02236399e+11,
        3.10008258e+10,  3.10008258e+10,  3.10008258e+10,  3.10008258e+10,
        3.10008258e+10,  3.10008258e+10,  3.10008258e+10,  3.10008258e+10,
        3.10008258e+10,  3.10008258e+10,  5.79619149e+10,  5.79619149e+10,
        5.79619149e+10,  5.79619149e+10,  5.79619149e+10,  5.79619149e+10,
        (...), -1.44368032e+09, -4.19616699e-02, -4.24880981e-02, -4.08172607e-02,
       -4.17327881e-02, -4.09812927e-02, -4.19616699e-02, -4.25262451e-02,
       -4.15306091e-02, -4.20017242e-02, -4.17938232e-02])

Given only the policy as features:
array([-0.04315836, -0.04372154, -0.04137428, -0.04213872, -0.03969142,
       -0.0404628 , -0.04198754, -0.04143859, -0.04178934, -0.04129638])

