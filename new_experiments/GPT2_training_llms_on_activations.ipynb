{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import re\n",
    "from peft import get_peft_model\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW,    TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "#from your_module import LoraConfig, get_peft_model  # Ensure you have the correct imports for LoRA\n",
    "\n",
    "from peft import LoraConfig\n",
    "\n",
    "#import the bits and bites optimizer again\n",
    "import bitsandbytes as bnb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import adamw\n",
    "from transformers import AdamW\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tokenizer, examples):\n",
    "    # Tokenize the question to create the model input\n",
    "    #sentence_to_append = \"Please place all of your calculations within the <<Calculations here>>, for example<<48/2=24>>. Inlcude the finsl answer after ####, such as ####NumberAnswer\"\n",
    "    \n",
    "    #for each row within the examples['question] dataset to each row append sentence to append\n",
    "    #examples['question'] = [x + sentence_to_append for x in examples['question']]\n",
    "\n",
    "    model_inputs = tokenizer(examples['question'], truncation=True, padding='max_length', max_length=64)\n",
    "    \n",
    "    # Tokenize the answer to create the labels\n",
    "    # The labels should be the input_ids from the tokenized answer\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['answer'], truncation=True, padding='max_length', max_length=64)\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2_fine_tune.py\t\t\t llama7b_lora_fine_tune.py\n",
      "GPT2_fine_tune_evaluate.py\t\t llama7b_lora_fine_tune_evaluate.py\n",
      "GPT2_training_llms_on_activations.ipynb  llama7b_lora_fine_tune_stable.py\n",
      "analyze_gradients.ipynb\t\t\t llama7b_partv8.py\n",
      "archive\t\t\t\t\t llm_checking_model_output.ipynb\n",
      "dense_activations.pkl\t\t\t lr_model.pkl\n",
      "gpu_parallel_training_starter.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effe9e81308348499332a9795d3f515c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "##############TRAIN###############\n",
    "# Correct dataset configuration and preprocessing\n",
    "data = load_dataset(\"gsm8k\", \"main\", split='train[:4000]')\n",
    "data = data.map(lambda e: preprocess_data(tokenizer, e), batched=True)\n",
    "##############TRAIN###############\n",
    "\n",
    "##############VALIDATION###############\n",
    "data_v_string = load_dataset(\"gsm8k\", \"main\", split='test')\n",
    "data_v = data_v_string.map(lambda e: preprocess_data(tokenizer, e), batched=True)\n",
    "##############VALIDATION###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Sparse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a model with the same configuration as the one you trained\n",
    "sparse_model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "sparse_model_state_dict = torch.load('../sparse_model_checkpoint_epoch_1.pth')\n",
    "sparse_model.load_state_dict(sparse_model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a model with the same configuration as the one you trained\n",
    "dense_model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "dense_model_state_dict = torch.load('../dense_model_checkpoint_epoch_1.pth')\n",
    "dense_model.load_state_dict(dense_model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#NOw generate the the activations only for the dense model, and save them to local\n",
    "def generate_activations(model, input_ids, batch_size=8):\n",
    "    activations = []\n",
    "    model.to(device)  # Ensure the model is on the correct device\n",
    "    for i in range(0, len(input_ids), batch_size):\n",
    "        batch_input_ids = input_ids[i:i+batch_size].to(device)  # Get batch of inputs\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            logits = model(batch_input_ids).logits\n",
    "        activations.append(logits.view(logits.size(0), -1).cpu().numpy())  # Move to CPU before converting to numpy\n",
    "    return np.concatenate(activations, axis=0)\n",
    "    #return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only taking in the input ids\n",
    "input_ids = torch.tensor(data['input_ids']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_activations = generate_activations(dense_model, input_ids)\n",
    "sparse_activations = generate_activations(sparse_model, input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "#Combine activations and create labels\n",
    "X = np.vstack((dense_activations, sparse_activations))\n",
    "y = np.array([1] * len(dense_activations) + [0] * len(sparse_activations))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dense_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "#create random 0s and 1s in y_pred\n",
    "#y_pred = np.random.randint(0, 2, size=y_test.shape)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the predicted labels vs. the actual labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test, label='Actual', alpha=0.7)\n",
    "plt.plot(y_pred, label='Predicted', alpha=0.7)\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Logistic Regression Predictions vs Actual')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model output of the logistic regressoin model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('lr_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lr_model, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
