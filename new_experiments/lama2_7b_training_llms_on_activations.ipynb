{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import re\n",
    "from peft import get_peft_model\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW,    TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "#from your_module import LoraConfig, get_peft_model  # Ensure you have the correct imports for LoRA\n",
    "\n",
    "from peft import LoraConfig\n",
    "\n",
    "#import the bits and bites optimizer again\n",
    "import bitsandbytes as bnb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import adamw\n",
    "from transformers import AdamW\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tokenizer, examples):\n",
    "\n",
    "    model_inputs = tokenizer(examples['question'], truncation=True, padding='max_length', max_length=64)\n",
    "    \n",
    "    # Tokenize the answer to create the labels\n",
    "    # The labels should be the input_ids from the tokenized answer\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['answer'], truncation=True, padding='max_length', max_length=64)\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_lora_layer(layer):\n",
    "    return hasattr(layer, 'lora_A') and hasattr(layer, 'lora_B')\n",
    "\n",
    "def get_lora_layers(model):\n",
    "    lora_layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if is_lora_layer(module):\n",
    "            lora_layers.append((name, module))\n",
    "    return lora_layers\n",
    "\n",
    "def generate_activations(model, input_ids, device, batch_size=8):\n",
    "    activations = []\n",
    "    model.to(device)  # Ensure the model is on the correct device\n",
    "    lora_layers = get_lora_layers(model)\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.view(output.size(0), -1).cpu().numpy())\n",
    "    \n",
    "    hooks = []\n",
    "    for name, layer in lora_layers:\n",
    "        hooks.append(layer.register_forward_hook(hook_fn))\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for i in range(0, len(input_ids), batch_size):\n",
    "            batch_input_ids = input_ids[i:i+batch_size].to(device)  # Get batch of inputs\n",
    "            model(batch_input_ids)\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    return np.concatenate(activations, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token = \"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=token, )\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "##############TRAIN###############\n",
    "# Correct dataset configuration and preprocessing\n",
    "data = load_dataset(\"math_dataset\",'algebra__linear_1d', split='train[:100]')\n",
    "data = data.map(lambda e: preprocess_data(tokenizer, e), batched=True)\n",
    "##############TRAIN###############\n",
    "\n",
    "#loading in the dataset\n",
    "\n",
    "\n",
    "\n",
    "# Set the device to GPU if available, otherwise CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#only taking in the input ids\n",
    "input_ids = torch.tensor(data['input_ids']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Sparse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading in sparse activations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#check if 'sparse_activations_lora_A1.pkl' exisits\n",
    "if os.path.exists('sparse_activations_lora_B1.pkl'):\n",
    "    print(\"loading in sparse activations\")\n",
    "    with open('sparse_activations_lora_B1.pkl', 'rb') as f:\n",
    "        sparse_activations = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    print('about to get model')\n",
    "    sparse_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=token, cache_dir='/workspace/.cache/huggingface/models/')\n",
    "    peft_model_id = '/workspace/llama7b_lora_fine_tune_sparse/'\n",
    "    sparse_model = PeftModel.from_pretrained(sparse_model, peft_model_id)\n",
    "    sparse_model.to(device)\n",
    "    \n",
    "    sparse_activations = generate_activations(sparse_model, input_ids, device)\n",
    "    #save the sparse activations to a pickle file\n",
    "    with open('sparse_activations_lora_B1.pkl', 'wb') as f:\n",
    "        pickle.dump(sparse_activations, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Dense model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to get model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e1e8829291475cba2debeaa7b84427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#check if 'sparse_activations_lora_A1.pkl' exisits\n",
    "if os.path.exists('dense_activations_lora_B1.pkl'):\n",
    "    print(\"loading in sparse activations\")\n",
    "    with open('sparse_activations_lora_A1.pkl', 'rb') as f:\n",
    "        sparse_activations = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    print('about to get model')\n",
    "    dense_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=token, cache_dir='/workspace/.cache/huggingface/models/')\n",
    "    peft_model_id = '/workspace/llama7b_lora_fine_tune_dense/'\n",
    "    dense_model = PeftModel.from_pretrained(dense_model, peft_model_id)\n",
    "    dense_model.to(device)\n",
    "    \n",
    "    dense_activations = generate_activations(dense_model, input_ids, device)\n",
    "    #save the sparse activations to a pickle file\n",
    "    with open('dense_activations_lora_B1.pkl', 'wb') as f:\n",
    "        pickle.dump(dense_activations, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Combine activations and create labels\n",
    "X = np.vstack((dense_activations, sparse_activations))\n",
    "y = np.array([1] * len(dense_activations) + [0] * len(sparse_activations))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dense_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "#create random 0s and 1s in y_pred\n",
    "#y_pred = np.random.randint(0, 2, size=y_test.shape)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the predicted labels vs. the actual labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test, label='Actual', alpha=0.7)\n",
    "plt.plot(y_pred, label='Predicted', alpha=0.7)\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Logistic Regression Predictions vs Actual')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model output of the logistic regressoin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('lr_model_updated_llama7b.pkl', 'wb') as file:\n",
    "    pickle.dump(lr_model, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
