{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a next-token predictor imitating (via self-supervised learning) some distribution D. Then we can express each of the lookup-table representations as follows:\n",
    "- Utility: keys = every possible sequence of <= N tokens for a context window of length N; values = how \"similar\" the last token is to the previous tokens\n",
    "    - How do we get this score??? \n",
    "    - Is this just memorizing the dataset lol (exhaustively to avoid non-generalization/overfit)\n",
    "- Reward: plus points for ???, value: sequence similarity to dataset\n",
    "    - I feel like this has the same problem as utility\n",
    "- Heuristic: e.g. current NLP techniques, later layers of NN\n",
    "    - What the NN model distills from training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
