{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn.conv import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup:\n",
    "- Starting point: just try to train classifier on RL policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DQN implementation\n",
    "\n",
    "# Define the Q-network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.state_dict()\n",
    "\n",
    "# Experience Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64, lr=1e-3, batch_size=64, gamma=0.99, replay_size=1000):\n",
    "        self.model = DQN(state_dim, action_dim, hidden_dim)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.replay_buffer = ReplayBuffer(replay_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.action_dim = action_dim\n",
    "    \n",
    "    def update(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        state, action, reward, next_state, done = self.replay_buffer.sample(self.batch_size)\n",
    "        \n",
    "        state = torch.FloatTensor(state)\n",
    "        next_state = torch.FloatTensor(next_state)\n",
    "        action = torch.LongTensor(action)\n",
    "        reward = torch.FloatTensor(reward)\n",
    "        done = torch.FloatTensor(done)\n",
    "\n",
    "        q_values = self.model(state)\n",
    "        next_q_values = self.model(next_state)\n",
    "        \n",
    "        q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "        next_q_value = next_q_values.max(1)[0]\n",
    "        expected_q_value = reward + self.gamma * next_q_value * (1 - done)\n",
    "        \n",
    "        loss = nn.MSELoss()(q_value, expected_q_value.detach())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state = torch.FloatTensor(np.expand_dims(state, 0))\n",
    "            q_value = self.model(state)\n",
    "            action = q_value.max(1)[1].item()\n",
    "        else:\n",
    "            action = random.randrange(self.action_dim)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(env_name=\"CartPole-v1\", episodes=500, epsilon_start=1.0, epsilon_final=0.01, \n",
    "              epsilon_decay=500, reward_function = None):\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "    agent = DQNAgent(state_dim, action_dim)\n",
    "    \n",
    "    epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * frame_idx / epsilon_decay)\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        while True:\n",
    "            epsilon = epsilon_by_frame(episode)\n",
    "            action = agent.act(state, epsilon)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            if reward_function:\n",
    "                reward = reward_function(state, action, next_state, done)\n",
    "            agent.replay_buffer.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            \n",
    "            agent.update()\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            # print(f\"Episode: {episode+1}, Total reward: {episode_reward}, Epsilon: {epsilon:.2f}\")\n",
    "\n",
    "        # Optional: Render the environment to visualize training progress\n",
    "        # if episode % 100 == 0:\n",
    "        #     render_env(env, agent)\n",
    "\n",
    "    env.close()\n",
    "    return agent\n",
    "\n",
    "# Optional: Function to render the environment with the current policy\n",
    "def render_env(env, agent):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state, 0)  # Using 0 epsilon for greedy action selection\n",
    "        # print(env.step(action))\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn(env, agent, episodes=10):\n",
    "    print(f\"Maximum reward: {env.spec.reward_threshold}\")\n",
    "    for episode in range(episodes):\n",
    "        # if episode == 0:\n",
    "        #     render_env(env, agent)\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.act(state, 0)  # Using 0 epsilon for greedy action selection\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "        print(f\"Episode: {episode+1}, Total reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "agent = train_dqn(env_name = env_name, episodes = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum reward: 475.0\n",
      "Episode: 1, Total reward: 500.0\n",
      "Episode: 2, Total reward: 500.0\n",
      "Episode: 3, Total reward: 500.0\n",
      "Episode: 4, Total reward: 500.0\n",
      "Episode: 5, Total reward: 500.0\n",
      "Episode: 6, Total reward: 500.0\n",
      "Episode: 7, Total reward: 500.0\n",
      "Episode: 8, Total reward: 500.0\n",
      "Episode: 9, Total reward: 500.0\n",
      "Episode: 10, Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.0.weight',\n",
       "              tensor([[ 1.1067,  1.5748, -0.8898,  0.5813],\n",
       "                      [ 0.8967, -0.5414, -6.2293, -1.2310],\n",
       "                      [ 0.4517, -0.2705, -0.2390,  0.0419],\n",
       "                      [ 0.0118, -0.2964, -0.5022, -0.3177],\n",
       "                      [-0.0810, -0.0312,  0.1967, -0.5733],\n",
       "                      [ 0.3461,  0.4033,  0.6180, -0.0125],\n",
       "                      [ 0.5193,  0.1527,  0.3628,  0.2688],\n",
       "                      [ 0.0599,  0.1889, -0.6775,  0.0249],\n",
       "                      [ 0.3614,  0.2492, -0.4951, -0.0232],\n",
       "                      [-0.1383,  0.6677,  6.0743,  1.1747],\n",
       "                      [ 0.8480,  0.9523,  4.7769,  1.4152],\n",
       "                      [ 0.3134,  0.4275, -0.1514, -0.1056],\n",
       "                      [ 0.6302,  0.2341,  0.0317,  0.0625],\n",
       "                      [-0.1284, -0.0282,  0.0093,  0.2146],\n",
       "                      [ 1.0972, -0.3998, -0.7634, -0.7361],\n",
       "                      [-0.1000, -0.2719, -1.1902, -0.5305],\n",
       "                      [-1.7267, -0.0569,  3.6636,  0.6081],\n",
       "                      [ 0.5125, -0.2337, -0.7214, -0.3466],\n",
       "                      [ 0.4492,  0.0848,  1.6556,  0.1081],\n",
       "                      [ 0.4772,  0.1647, -0.9974,  0.4249],\n",
       "                      [-0.9521, -0.2708, -1.9297, -0.3249],\n",
       "                      [-1.6637,  0.2246,  1.9698,  0.8152],\n",
       "                      [-1.1048, -0.9583, -5.0336, -1.5614],\n",
       "                      [-0.3366,  0.4195,  0.3403,  0.0942],\n",
       "                      [ 0.3976, -0.3022, -0.5200,  0.2494],\n",
       "                      [-0.3334,  0.6568,  0.7417,  0.1862],\n",
       "                      [-0.0530, -0.1199,  0.6569,  0.0913],\n",
       "                      [ 0.3447,  0.3041, -0.6079, -0.0892],\n",
       "                      [ 0.4176,  0.1937, -0.3547, -0.1972],\n",
       "                      [-0.8061,  0.1417,  4.3487,  0.7658],\n",
       "                      [-1.0802, -1.3377, -4.8715, -1.1505],\n",
       "                      [-0.7655,  0.8836,  5.7526,  1.4106],\n",
       "                      [-0.1811,  0.6617,  5.1480,  2.0181],\n",
       "                      [ 3.4616,  0.5413, -2.6478, -0.5980],\n",
       "                      [-0.1943, -0.2666, -0.5728, -0.2319],\n",
       "                      [ 0.6629, -0.2789,  0.2081, -0.2473],\n",
       "                      [ 0.4959,  0.2489,  0.8353,  0.2865],\n",
       "                      [ 0.1256,  0.4647, -0.5557,  0.2440],\n",
       "                      [ 0.0110,  0.3079, -0.0513, -0.3355],\n",
       "                      [ 0.0209,  0.0166, -0.1017, -0.2145],\n",
       "                      [ 0.4974,  0.5090,  0.0749,  0.3419],\n",
       "                      [ 0.3128,  0.3132,  1.8538,  0.4949],\n",
       "                      [ 0.5521, -0.3445, -0.6999, -0.2083],\n",
       "                      [ 1.5467,  0.9740, -1.0911,  0.4512],\n",
       "                      [ 0.3072,  1.7367,  4.5902,  1.3516],\n",
       "                      [-0.0488, -0.4555,  0.0606, -0.0745],\n",
       "                      [ 0.8669, -0.2366, -0.7788, -0.1382],\n",
       "                      [-0.0855,  0.4922,  6.5526,  1.6664],\n",
       "                      [ 0.1911,  0.4324,  0.1078, -0.2581],\n",
       "                      [ 0.6301,  0.0696, -0.4082,  0.0248],\n",
       "                      [-1.0154, -0.2519,  4.6584,  0.5781],\n",
       "                      [-3.0680, -0.2020,  1.8849,  0.6041],\n",
       "                      [-0.8020, -0.6132,  0.2812, -0.3443],\n",
       "                      [-2.0720, -0.1338,  1.0727,  0.4861],\n",
       "                      [ 0.2262, -0.5166, -5.5905, -1.1253],\n",
       "                      [ 0.3539, -1.1058, -4.5638, -0.7242],\n",
       "                      [ 0.0549, -0.0282, -0.1934,  0.0899],\n",
       "                      [-1.6613, -0.5517,  1.4469, -0.3125],\n",
       "                      [-0.5566, -0.8573, -4.5234, -1.4610],\n",
       "                      [-0.0813,  0.3399,  0.1984, -0.4003],\n",
       "                      [ 0.4577,  0.4983,  0.5180,  0.0140],\n",
       "                      [-0.6754, -0.4900, -4.2945, -0.6635],\n",
       "                      [ 0.5928,  0.1956, -0.7150,  0.1697],\n",
       "                      [-0.2326,  0.5967, -0.0701,  0.2798]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([ 1.8472, -0.8372,  1.1687,  1.5631,  1.4348,  1.3177,  1.2846,  1.2387,\n",
       "                       1.5001, -1.5800,  1.9482,  1.5093,  1.5877,  1.4429,  1.4791,  1.7223,\n",
       "                       0.8415,  1.3868,  0.8462,  1.3458,  1.1314,  1.0546,  2.0590,  1.2303,\n",
       "                       1.4324,  0.9079,  1.4602,  1.4607,  1.3654, -1.7256, -1.0149,  1.5948,\n",
       "                       1.4446, -0.3728,  1.6039,  1.6915,  1.2910,  1.6365,  1.4945,  1.5241,\n",
       "                       1.5548,  0.8659,  1.2731,  1.4991, -0.9788,  1.1462,  1.4529, -1.4105,\n",
       "                       1.7044,  1.3509,  0.9628,  0.4159,  0.3042, -0.2678, -1.1390, -1.7859,\n",
       "                      -0.4966, -0.6955,  2.0623,  1.5947,  1.4381,  0.1177,  1.3693,  1.5512])),\n",
       "             ('fc.2.weight',\n",
       "              tensor([[-1.2119, -3.6479,  0.8292,  ..., -2.2846,  1.2898,  0.7868],\n",
       "                      [ 0.0094, -0.0910, -0.0286,  ...,  0.1119, -0.0262, -0.0118],\n",
       "                      [-1.4346,  0.0898,  0.0077,  ..., -2.8523, -0.8109, -0.4398],\n",
       "                      ...,\n",
       "                      [-2.4598, -3.9725,  0.5939,  ..., -2.7063,  0.7389,  0.6887],\n",
       "                      [-2.0049, -5.0652,  0.8495,  ..., -2.9438,  1.0145,  0.7922],\n",
       "                      [-0.0306, -0.0531, -0.1428,  ..., -0.0432,  0.0502, -0.0153]])),\n",
       "             ('fc.2.bias',\n",
       "              tensor([ 0.9601, -0.0786, -0.3370,  0.4343,  0.0356,  0.0915,  1.7941,  1.9173,\n",
       "                       0.7202, -0.0822,  0.0598,  0.9056,  1.5644,  0.6200,  0.4936, -0.0688,\n",
       "                       1.5849,  0.9915,  0.5043, -1.4423,  0.8097,  1.3217,  0.9886,  0.9457,\n",
       "                       0.4216,  1.0970,  1.0190, -0.0907,  1.1134,  1.0067, -0.1289,  1.0073,\n",
       "                       0.4614,  1.1029,  1.0422,  0.5197,  1.0764, -0.0854,  1.0219,  2.0123,\n",
       "                       0.9517,  0.9633, -0.0547,  0.4927,  0.4795,  0.8074,  1.0180,  0.0244,\n",
       "                      -0.0677, -0.0795,  0.6839,  0.8683,  1.0214,  0.9763,  1.0315, -0.9676,\n",
       "                      -0.6777,  0.9733, -0.0914, -0.5825,  0.3685,  0.8842,  0.8994, -0.0725])),\n",
       "             ('fc.4.weight',\n",
       "              tensor([[ 2.8017e+00, -5.1674e-02,  1.4734e+00,  4.5352e+00, -1.0310e-01,\n",
       "                       -6.7159e-02, -8.1934e-01, -1.0229e-01,  3.0869e+00,  3.1708e-02,\n",
       "                       -8.0547e-02,  3.0160e+00, -2.5984e+00,  3.8916e+00,  4.0539e+00,\n",
       "                        9.3933e-02, -2.5838e+00,  2.9116e+00,  3.6089e+00, -4.3517e+00,\n",
       "                       -3.6630e+00,  2.5078e+00,  3.6565e+00, -1.5830e+00,  4.9285e+00,\n",
       "                        2.7505e+00,  3.8458e+00, -1.0164e-03,  2.5252e+00,  2.4601e+00,\n",
       "                        3.5822e-02,  2.7989e+00,  4.0088e+00,  2.5008e+00,  2.7185e+00,\n",
       "                        3.6381e+00,  2.7401e+00, -1.2131e-01,  2.6789e+00, -4.9860e-01,\n",
       "                        2.4733e+00,  3.1453e+00,  1.6171e-02,  3.8827e+00,  3.9347e+00,\n",
       "                        2.7487e+00,  2.6523e+00, -1.2922e-02, -1.0693e-02, -6.5625e-02,\n",
       "                        4.6487e+00,  2.9709e+00,  2.6767e+00,  3.4873e+00,  4.0878e+00,\n",
       "                       -1.8567e+00, -4.9992e+00,  5.3188e-01, -1.1386e-01, -4.1776e+00,\n",
       "                        4.4394e+00,  3.3093e+00,  2.4138e+00,  3.2768e-03],\n",
       "                      [ 3.0341e+00, -2.7486e-03, -4.8190e+00,  4.1446e+00, -3.4759e-02,\n",
       "                        7.2272e-02, -3.4695e+00, -3.6089e+00,  2.8650e+00,  4.1411e-02,\n",
       "                       -9.0004e-02,  2.9249e+00,  5.6852e-02,  3.2280e+00,  3.7400e+00,\n",
       "                       -1.2150e-02,  2.5195e-01,  2.8811e+00,  3.4889e+00, -2.5735e+00,\n",
       "                        4.0019e+00,  2.6562e+00,  1.2669e+00,  4.4217e+00,  4.2905e+00,\n",
       "                        2.8460e+00,  3.1826e+00,  6.2912e-02,  2.6090e+00,  2.9241e+00,\n",
       "                        5.3696e-02,  2.7844e+00,  3.3702e+00,  2.6782e+00,  2.9317e+00,\n",
       "                        3.1549e+00,  2.9588e+00, -1.0920e-03,  2.9424e+00, -3.5126e+00,\n",
       "                        2.7626e+00,  2.8311e+00, -9.6864e-03,  3.5456e+00,  3.3955e+00,\n",
       "                        2.8515e+00,  2.8372e+00, -5.4551e-02,  2.1920e-02, -2.1162e-02,\n",
       "                        3.0370e+00,  2.9453e+00,  2.8871e+00,  3.1143e+00,  3.2240e+00,\n",
       "                       -6.4100e+00, -9.3454e-01,  2.7996e+00, -6.3330e-02, -2.7674e-01,\n",
       "                        3.8782e+00,  3.2411e+00,  2.7586e+00,  4.2501e-02]])),\n",
       "             ('fc.4.bias', tensor([1.1357, 1.0837]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dqn(gym.make(\"CartPole-v1\"), agent)\n",
    "agent.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coherence classifier\n",
    "\n",
    "#agent.model.get_weights()\n",
    "\n",
    "# Define a simple GCN model\n",
    "from torch_geometric.data import Data\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super(GCN, self).__init__()\n",
    "        # Define the GCN layers\n",
    "        self.conv1 = GCNConv(data.num_node_features, 4)  # Input features to hidden\n",
    "        self.conv2 = GCNConv(4, 2)  # Hidden to output features\n",
    "        self.data = data\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # Pass data through the first GCN layer, then apply ReLU\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        # Pass data through the second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def nn_to_data(model: nn.Module) -> Data:\n",
    "    edges = []\n",
    "    node_features = []\n",
    "\n",
    "    # Counter for global neuron index\n",
    "    global_neuron_index = 0\n",
    "\n",
    "    # Iterate over each layer in the network\n",
    "    base = next(model.children())\n",
    "    if isinstance(base, nn.Sequential):\n",
    "        layers = base.children()\n",
    "    else:\n",
    "        layers = model.children()\n",
    "\n",
    "    if isinstance(base, nn.Sequential):\n",
    "        input_dim = base[0].in_features\n",
    "        node_features = np.zeros(input_dim)\n",
    "\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            # Update edges based on the weight matrix\n",
    "            for i in range(layer.weight.shape[1]):  # Input neurons\n",
    "                for j in range(layer.weight.shape[0]):  # Output neurons\n",
    "                    edges.append((global_neuron_index + i, global_neuron_index + layer.weight.shape[1] + j))\n",
    "            \n",
    "            # Update node features (e.g., biases)\n",
    "            extension = layer.bias.detach().numpy()\n",
    "            node_features = np.append(node_features, extension)\n",
    "            \n",
    "            # Update the global neuron index\n",
    "            global_neuron_index += layer.weight.shape[1]\n",
    "\n",
    "    # Convert lists to PyTorch tensors\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(node_features, dtype=torch.float).view(-1, 1)\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data = nn_to_data(agent.model)\n",
    "gcn = GCN(data)\n",
    "# data.x.shape, data.edge_index.shape\n",
    "# print(data.x)\n",
    "\n",
    "#Debug\n",
    "out_of_bounds = data.edge_index >= data.x.shape[0]\n",
    "if out_of_bounds.any():\n",
    "    print(\"Out-of-bounds indices found at locations:\")\n",
    "    print(data.edge_index[:, out_of_bounds.any(dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generation\n",
    "env = gym.make(env_name)\n",
    "def deterministic_random(*args, lb = -1, ub = 1):\n",
    "    unique_seed = f\"{args}\".encode(\"utf-8\")\n",
    "    random.seed(unique_seed)\n",
    "    return random.uniform(lb, ub)\n",
    "\n",
    "NUM_TRAIN_R_FUNCS = 100\n",
    "NUM_EPS_TRAIN_R = 100\n",
    "URS_r_funcs = [lambda s, a, ns, d: deterministic_random(s, a, ns, d) for _ in range(NUM_TRAIN_R_FUNCS)]\n",
    "URS_agents = [train_dqn(env_name = env_name, \n",
    "                        episodes=NUM_EPS_TRAIN_R, reward_function=r_func) for r_func in URS_r_funcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([134, 1])\n",
      "Epoch 1: Average Train Loss: 0.40541577302701626, Average Test Loss: 0.0537006069553172\n",
      "Epoch 2: Average Train Loss: 0.07264251570584701, Average Test Loss: 0.021336334023372316\n",
      "Epoch 3: Average Train Loss: 0.07250669127260512, Average Test Loss: 0.011036095714824867\n",
      "Epoch 4: Average Train Loss: 0.0571737502666406, Average Test Loss: 0.011023389485248104\n",
      "Epoch 5: Average Train Loss: 0.054839500761868276, Average Test Loss: 0.008242949860520455\n",
      "Epoch 6: Average Train Loss: 0.05347820636596641, Average Test Loss: 0.0062461225085147735\n",
      "Epoch 7: Average Train Loss: 0.050224280575129045, Average Test Loss: 0.004865015919730098\n",
      "Epoch 8: Average Train Loss: 0.04852196569670415, Average Test Loss: 0.003984942406126279\n",
      "Epoch 9: Average Train Loss: 0.04454295151290797, Average Test Loss: 0.003437603973772241\n",
      "Epoch 10: Average Train Loss: 0.0442975319416596, Average Test Loss: 0.0031744233318995894\n",
      "Epoch 11: Average Train Loss: 0.04262183145602867, Average Test Loss: 0.002960501896126999\n",
      "Epoch 12: Average Train Loss: 0.0425536371707679, Average Test Loss: 0.002845730998359741\n",
      "Epoch 13: Average Train Loss: 0.04092757792406125, Average Test Loss: 0.0027953354200761283\n",
      "Epoch 14: Average Train Loss: 0.04021004145401621, Average Test Loss: 0.002732951212058765\n",
      "Epoch 15: Average Train Loss: 0.0394829354326923, Average Test Loss: 0.0027061775973393765\n",
      "Epoch 16: Average Train Loss: 0.037921403045570304, Average Test Loss: 0.0027199802264938457\n",
      "Epoch 17: Average Train Loss: 0.036497813990859204, Average Test Loss: 0.002723489338314522\n",
      "Epoch 18: Average Train Loss: 0.03619517104498051, Average Test Loss: 0.002708466281842803\n",
      "Early stopping at epoch 18\n"
     ]
    }
   ],
   "source": [
    "UPS_agents = [DQNAgent(env.observation_space.shape[0], env.action_space.n) for _ in range(NUM_TRAIN_R_FUNCS)]\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool, GCNConv\n",
    "\n",
    "class GraphLevelGCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(GraphLevelGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.linear = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # Aggregate node features to graph-level features\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Make a binary classification prediction\n",
    "        x = self.linear(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Training loop\n",
    "URS_data = [nn_to_data(agent.model) for agent in URS_agents]\n",
    "print(URS_data[0].x.shape)\n",
    "UPS_data = [nn_to_data(agent.model) for agent in UPS_agents]\n",
    "assert URS_data[0].x.shape == UPS_data[0].x.shape\n",
    "indices = np.random.permutation(len(URS_data) + len(UPS_data))\n",
    "\n",
    "data = [URS_data[i] if i < len(URS_data) else UPS_data[i - len(URS_data)] for i in indices]\n",
    "for i in range(len(data)):\n",
    "    data[i].y = 1.0 if indices[i] < len(URS_data) else 0.0 # Binary labels for each node; 1 = URS, 0 = UPS\n",
    "\n",
    "train_data_ratio = 0.8\n",
    "train_data, test_data = data[:int(train_data_ratio * len(data))], data[int(train_data_ratio * len(data)):]\n",
    "# Loss and optimizer\n",
    "num_node_features = 1 # just the bias term\n",
    "model = GraphLevelGCN(num_node_features)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 20\n",
    "# Set the number of epochs to wait for early stopping\n",
    "patience = 3\n",
    "# Initialize variables for early stopping\n",
    "best_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_train_loss = 0\n",
    "    for datapt in train_data:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(f\"datapt.x shape: {datapt.x.shape}\")  # Should be [num_nodes, num_node_features]\n",
    "        # print(f\"datapt.edge_index shape: {datapt.edge_index.shape}\")  # Should be [2, num_edges]\n",
    "        out = model.forward(datapt)\n",
    "        # print(out.size())\n",
    "        # print(torch.tensor([[datapt.y]]).size())\n",
    "        loss = criterion(out, torch.tensor([[datapt.y]]))  # Adjust shape as necessary\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_train_loss += loss.item()\n",
    "    avg_train_loss /= len(train_data)\n",
    "\n",
    "    avg_test_loss = 0\n",
    "    for datapt in test_data:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(datapt)\n",
    "            loss = criterion(out, torch.tensor([[datapt.y]]))\n",
    "            avg_test_loss += loss.item()\n",
    "    avg_test_loss /= len(test_data)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Average Train Loss: {avg_train_loss}, Average Test Loss: {avg_test_loss}')\n",
    "    \n",
    "    # Early Stopping\n",
    "    if avg_test_loss < best_loss:\n",
    "        best_loss = avg_test_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9998]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0042]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test GCN model on a \"more powerful\" NN\n",
    "print(model.forward(URS_data[0]))\n",
    "print(model.forward(UPS_data[0]))\n",
    "print(model.forward(nn_to_data(agent.model)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
