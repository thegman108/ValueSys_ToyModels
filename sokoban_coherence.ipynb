{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn.conv import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup:\n",
    "- Starting point: just try to train classifier on RL policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DQN implementation\n",
    "\n",
    "# Define the Q-network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.state_dict()\n",
    "\n",
    "# Experience Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64, lr=1e-3, batch_size=64, gamma=0.99, replay_size=1000):\n",
    "        self.model = DQN(state_dim, action_dim, hidden_dim)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.replay_buffer = ReplayBuffer(replay_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.action_dim = action_dim\n",
    "    \n",
    "    def update(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        state, action, reward, next_state, done = self.replay_buffer.sample(self.batch_size)\n",
    "        \n",
    "        state = torch.FloatTensor(state)\n",
    "        next_state = torch.FloatTensor(next_state)\n",
    "        action = torch.LongTensor(action)\n",
    "        reward = torch.FloatTensor(reward)\n",
    "        done = torch.FloatTensor(done)\n",
    "\n",
    "        q_values = self.model(state)\n",
    "        next_q_values = self.model(next_state)\n",
    "        \n",
    "        q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "        next_q_value = next_q_values.max(1)[0]\n",
    "        expected_q_value = reward + self.gamma * next_q_value * (1 - done)\n",
    "        \n",
    "        loss = nn.MSELoss()(q_value, expected_q_value.detach())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state = torch.FloatTensor(np.expand_dims(state, 0))\n",
    "            q_value = self.model(state)\n",
    "            action = q_value.max(1)[1].item()\n",
    "        else:\n",
    "            action = random.randrange(self.action_dim)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(env_name=\"CartPole-v1\", episodes=500, epsilon_start=1.0, epsilon_final=0.01, \n",
    "              epsilon_decay=500):\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "    agent = DQNAgent(state_dim, action_dim)\n",
    "    \n",
    "    epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * frame_idx / epsilon_decay)\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        while True:\n",
    "            epsilon = epsilon_by_frame(episode)\n",
    "            action = agent.act(state, epsilon)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.replay_buffer.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            \n",
    "            agent.update()\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            # print(f\"Episode: {episode+1}, Total reward: {episode_reward}, Epsilon: {epsilon:.2f}\")\n",
    "\n",
    "        # Optional: Render the environment to visualize training progress\n",
    "        # if episode % 100 == 0:\n",
    "        #     render_env(env, agent)\n",
    "\n",
    "    env.close()\n",
    "    return agent\n",
    "\n",
    "# Optional: Function to render the environment with the current policy\n",
    "def render_env(env, agent):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state, 0)  # Using 0 epsilon for greedy action selection\n",
    "        # print(env.step(action))\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn(env, agent, episodes=10):\n",
    "    print(f\"Maximum reward: {env.spec.reward_threshold}\")\n",
    "    for episode in range(episodes):\n",
    "        # if episode == 0:\n",
    "        #     render_env(env, agent)\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.act(state, 0)  # Using 0 epsilon for greedy action selection\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "        print(f\"Episode: {episode+1}, Total reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = train_dqn(episodes = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum reward: 475.0\n",
      "Episode: 1, Total reward: 65.0\n",
      "Episode: 2, Total reward: 249.0\n",
      "Episode: 3, Total reward: 200.0\n",
      "Episode: 4, Total reward: 340.0\n",
      "Episode: 5, Total reward: 500.0\n",
      "Episode: 6, Total reward: 206.0\n",
      "Episode: 7, Total reward: 500.0\n",
      "Episode: 8, Total reward: 88.0\n",
      "Episode: 9, Total reward: 132.0\n",
      "Episode: 10, Total reward: 303.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.0.weight',\n",
       "              tensor([[ 8.0815e-01,  2.2713e-01, -1.5328e+00, -5.7343e-01],\n",
       "                      [ 5.3673e-01, -1.4522e-01, -4.6750e-01, -6.8723e-01],\n",
       "                      [-9.3924e-02, -1.8958e-02,  3.8947e-01, -3.0018e-01],\n",
       "                      [-1.5461e-01, -3.5016e-01, -9.7916e-02, -1.6390e-01],\n",
       "                      [-5.3706e-01, -9.6581e-01,  4.8666e-01,  8.0225e-01],\n",
       "                      [ 1.8764e-01,  8.2671e-02, -1.0861e+00, -6.7551e-01],\n",
       "                      [-3.3833e-02, -3.0430e-01,  4.4604e-01, -2.2593e-01],\n",
       "                      [-1.2941e-03, -2.2370e-01,  2.2220e-01,  1.1660e-01],\n",
       "                      [-8.6939e-04,  2.2074e-01,  4.9737e-01,  1.0742e-02],\n",
       "                      [ 7.9584e-01,  3.4847e-01, -1.1259e+00, -4.8410e-01],\n",
       "                      [ 3.1187e-01,  1.9612e-01, -1.3736e+00, -2.8820e-01],\n",
       "                      [ 5.9451e-01, -3.2977e-01, -2.1979e-01, -3.7078e-02],\n",
       "                      [ 9.7603e-01,  3.8013e-01, -7.9632e-01, -3.5517e-01],\n",
       "                      [-1.3773e-01,  5.9828e-01,  6.6347e-01,  2.9539e-01],\n",
       "                      [ 1.4633e-01, -1.1105e-01,  3.5375e-01, -4.3065e-01],\n",
       "                      [-1.0395e-01,  2.4723e-01,  7.2291e-02,  2.6286e-01],\n",
       "                      [ 4.5123e-01,  2.9768e-01, -1.2644e+00, -8.5988e-01],\n",
       "                      [-1.3476e-01, -3.1110e-01,  2.3521e-01, -2.6741e-01],\n",
       "                      [-6.6430e-02,  4.9485e-01,  7.6202e-01, -1.9297e-01],\n",
       "                      [-1.2193e-01,  2.4769e-01, -1.7991e-02,  3.6549e-01],\n",
       "                      [-3.6499e-02,  2.8654e-01, -2.4030e-02, -1.0788e-01],\n",
       "                      [ 4.3773e-01,  8.9850e-02, -7.8176e-01, -6.2148e-01],\n",
       "                      [-6.0366e-02,  3.3140e-01, -2.7658e-01,  3.9815e-01],\n",
       "                      [-1.1905e-02,  5.4850e-01,  5.1359e-01,  7.5174e-02],\n",
       "                      [-5.4911e-02,  1.7323e-01, -1.0737e-01,  7.9022e-02],\n",
       "                      [-3.8339e-01,  3.6197e-01,  6.7162e-01,  3.1478e-01],\n",
       "                      [-1.9312e-01,  3.3412e-01,  3.6843e-01, -2.1465e-01],\n",
       "                      [-7.6895e-01, -5.2203e-02,  1.4980e+00,  1.0031e+00],\n",
       "                      [-9.3456e-03, -9.7595e-02, -7.1644e-02, -7.4711e-02],\n",
       "                      [-1.4615e-01, -1.5332e-01,  9.9911e-02,  1.0516e-02],\n",
       "                      [ 2.7358e-01,  2.8202e-01, -1.3734e+00, -6.1399e-01],\n",
       "                      [-8.0902e-01, -5.5545e-01,  1.2020e+00,  6.4980e-01],\n",
       "                      [ 1.9181e-01, -2.1791e-01,  2.6813e-02, -8.6764e-02],\n",
       "                      [-4.7228e-01,  3.7450e-01,  3.9076e-01, -3.7563e-01],\n",
       "                      [ 2.0548e-02,  2.5386e-01, -6.6259e-01, -5.8776e-01],\n",
       "                      [ 2.1110e-01, -1.7951e-02,  4.6090e-01,  2.0880e-01],\n",
       "                      [-1.9497e-01, -2.5940e-01,  4.8246e-01, -1.5331e-01],\n",
       "                      [ 3.6259e-01,  1.8928e-01,  2.4190e-01,  7.9194e-03],\n",
       "                      [-2.9250e-01,  4.2023e-01,  3.1150e-01, -1.7752e-01],\n",
       "                      [ 5.4986e-01,  1.4967e-01, -1.0719e+00, -5.8403e-01],\n",
       "                      [ 2.1860e-01,  2.9051e-01, -1.8943e-01,  9.7271e-03],\n",
       "                      [-2.8614e-02,  4.7177e-01,  8.5804e-01, -5.3719e-02],\n",
       "                      [-4.7967e-01, -4.2587e-01, -8.0523e-02, -4.6550e-01],\n",
       "                      [-3.1547e-01,  2.1845e-01,  1.5281e-01, -2.0352e-01],\n",
       "                      [-6.0772e-01, -2.5870e-01,  9.9683e-01,  7.4257e-01],\n",
       "                      [ 2.9666e-01, -9.5163e-02, -3.1960e-01, -1.4121e-01],\n",
       "                      [-2.2669e-01, -2.0980e-01,  5.0518e-01, -2.1169e-01],\n",
       "                      [ 8.1012e-01, -2.9294e-01,  5.3203e-02,  3.1182e-01],\n",
       "                      [ 4.3877e-01, -1.1049e-02,  6.4979e-01,  1.4400e-01],\n",
       "                      [-2.6943e-01,  1.4870e-01, -8.0689e-02, -4.2099e-02],\n",
       "                      [ 1.2553e+00,  3.7252e-01, -1.3744e+00, -4.7184e-01],\n",
       "                      [ 2.6972e-01, -3.0245e-01, -6.6012e-02, -3.3860e-01],\n",
       "                      [ 3.2867e-01, -3.5868e-01,  5.7818e-01, -2.8306e-01],\n",
       "                      [ 5.9979e-02,  2.8546e-01,  4.4015e-01, -1.4094e-01],\n",
       "                      [ 7.4502e-01,  2.2450e-01, -4.9347e-01, -3.6702e-01],\n",
       "                      [-1.5446e-01,  1.1092e-01,  3.6482e-01, -4.4631e-02],\n",
       "                      [ 3.4062e-01, -7.1239e-02,  1.4770e-01,  9.8188e-02],\n",
       "                      [ 1.0882e+00, -1.1397e-01, -7.2987e-01, -8.1076e-01],\n",
       "                      [-3.6085e-01,  1.4736e-01,  1.6347e-02,  1.3718e-01],\n",
       "                      [ 7.4525e-01,  3.3511e-01, -1.3019e+00, -7.2281e-01],\n",
       "                      [ 1.5502e-02,  5.2790e-01,  8.2397e-01, -7.4333e-02],\n",
       "                      [ 1.1573e-01, -2.8038e-02,  5.2033e-01, -2.1683e-01],\n",
       "                      [-1.0227e-01,  2.7513e-01,  4.1975e-02, -1.1595e-02],\n",
       "                      [-9.1432e-01,  2.4918e-02,  1.3401e+00,  9.0174e-01]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([ 0.2303,  0.3525,  0.4485,  0.5629,  0.3183,  0.3102, -0.4363,  0.9168,\n",
       "                      -0.3754, -0.1433,  0.2520,  0.5767,  0.0903,  0.4649,  0.8379,  0.6057,\n",
       "                      -0.0247,  0.7899,  0.8555, -0.4973,  0.6531, -0.3206,  0.6444,  0.2310,\n",
       "                      -0.3069,  0.6756,  0.6802, -0.3156, -0.4468,  0.6228,  0.0579, -0.4378,\n",
       "                       0.4414,  0.9275,  0.3838,  0.8350,  0.5413, -0.4864,  0.7257, -0.1495,\n",
       "                       0.5143,  0.3321,  0.5018,  0.5122,  0.1019, -0.3281,  0.4178,  0.4927,\n",
       "                       0.6905,  0.7150, -0.1561, -0.4805,  0.8046,  0.6049, -0.2510,  0.5623,\n",
       "                       0.3172,  0.2225, -0.3513,  0.3013,  0.6959,  0.7510,  0.5748, -0.3606])),\n",
       "             ('fc.2.weight',\n",
       "              tensor([[-0.2852, -0.1408,  0.2294,  ...,  0.3757,  0.2586, -0.6853],\n",
       "                      [-0.2436, -0.2484,  0.0181,  ...,  0.2789,  0.2619, -0.6598],\n",
       "                      [-0.3494, -0.3094,  0.0410,  ...,  0.4933,  0.2902, -0.6848],\n",
       "                      ...,\n",
       "                      [ 0.0385, -0.0820,  0.0068,  ..., -0.1066, -0.0561,  0.0592],\n",
       "                      [-0.3613, -0.1406,  0.2183,  ...,  0.2973,  0.4786, -0.8559],\n",
       "                      [-0.0847, -0.0714,  0.0395,  ..., -0.0447, -0.1123,  0.0764]])),\n",
       "             ('fc.2.bias',\n",
       "              tensor([ 0.4533,  0.3892,  0.3577,  0.0311,  0.0240, -0.0606,  0.1147,  0.2838,\n",
       "                       0.4030,  0.0094, -0.0101,  0.3671, -0.0247,  0.0531,  0.4233, -0.0478,\n",
       "                      -0.0415,  0.4342,  0.0189,  0.2951, -0.0835,  0.3955,  0.0168,  0.0890,\n",
       "                       0.0576, -0.0191,  0.0008, -0.0231,  0.3184,  0.3749,  0.2093,  0.3543,\n",
       "                       0.3944,  0.4775,  0.3692,  0.0052,  0.0496, -0.0969,  0.2625, -0.1288,\n",
       "                       0.2704,  0.2765, -0.0212,  0.3098,  0.0450,  0.0161,  0.0488,  0.0025,\n",
       "                       0.2459,  0.4384, -0.0384, -0.0639,  0.2443,  0.2936,  0.4733,  0.3768,\n",
       "                       0.0475,  0.3394,  0.3857, -0.0834, -0.0555,  0.0767,  0.2317,  0.0616])),\n",
       "             ('fc.4.weight',\n",
       "              tensor([[ 4.0663e-01,  4.4079e-01,  3.5765e-01, -6.1840e-02, -3.9420e-02,\n",
       "                        6.4774e-04, -9.4895e-02,  5.2062e-01,  4.1235e-01, -9.3018e-02,\n",
       "                       -8.3422e-02,  4.5027e-01,  1.1124e-01, -1.8760e-02,  4.8829e-01,\n",
       "                        3.4816e-02, -4.1296e-02,  2.8906e-01,  3.8317e-02,  2.4468e-01,\n",
       "                        6.1681e-02,  1.6982e-01, -3.1002e-02,  6.1087e-02, -2.9195e-02,\n",
       "                       -6.1661e-02,  3.2317e-02,  4.6506e-02,  4.1381e-01,  5.3228e-01,\n",
       "                        4.8817e-01,  4.6919e-01,  4.9330e-01,  2.4854e-01,  5.8580e-01,\n",
       "                       -7.3223e-03, -2.2567e-02, -3.9315e-02,  5.5239e-01,  1.1427e-01,\n",
       "                        5.5034e-01,  5.8190e-01, -7.5258e-02,  5.1612e-01, -9.0003e-02,\n",
       "                        4.4925e-02, -7.0299e-02,  9.1324e-02,  4.9251e-01,  3.5570e-01,\n",
       "                        3.9336e-02, -2.3298e-02,  3.8528e-01,  5.1382e-01,  2.7636e-01,\n",
       "                        3.0010e-01, -8.4506e-02,  4.9520e-01,  3.8761e-01,  8.6467e-02,\n",
       "                        6.6561e-02, -3.4156e-02,  7.4805e-01, -1.2390e-01],\n",
       "                      [ 4.4179e-01,  4.8970e-01,  4.8088e-01, -7.8138e-02, -9.2592e-02,\n",
       "                       -4.6015e-02,  1.9531e-03, -4.1210e-01,  5.4297e-01, -6.7965e-02,\n",
       "                       -2.3674e-02,  5.6155e-01,  1.0138e-01,  3.6369e-04,  3.5980e-01,\n",
       "                       -1.0533e-01,  2.7126e-02,  5.5488e-01, -5.5815e-02,  6.2991e-01,\n",
       "                       -6.0046e-02, -5.0485e-01, -7.7253e-02, -1.0329e-01, -1.3458e-03,\n",
       "                       -2.5602e-02, -9.5167e-02,  1.1097e-01,  5.0529e-01,  5.5743e-01,\n",
       "                        5.3549e-01,  4.7138e-01,  4.0189e-01,  5.4636e-01,  4.6664e-01,\n",
       "                        3.1664e-02, -9.3863e-02,  9.0159e-02,  4.0412e-01, -2.4351e-03,\n",
       "                        4.4612e-01,  3.3617e-01,  5.7415e-02,  4.6279e-01,  3.3142e-02,\n",
       "                       -4.3276e-02, -4.4167e-02, -9.1499e-02,  5.3470e-01,  5.0021e-01,\n",
       "                        5.3114e-02, -3.8455e-02,  4.9501e-01,  5.4965e-01,  5.4699e-01,\n",
       "                        4.9342e-01,  3.5768e-02,  3.7522e-01,  5.6233e-01, -4.5704e-02,\n",
       "                       -7.8085e-02,  1.2662e-02,  3.7145e-01, -5.9906e-03]])),\n",
       "             ('fc.4.bias', tensor([0.0493, 0.4380]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dqn(gym.make(\"CartPole-v1\"), agent)\n",
    "agent.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coherence classifier\n",
    "\n",
    "#agent.model.get_weights()\n",
    "\n",
    "# Define a simple GCN model\n",
    "from torch_geometric.data import Data\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super(GCN, self).__init__()\n",
    "        # Define the GCN layers\n",
    "        self.conv1 = GCNConv(data.num_node_features, 4)  # Input features to hidden\n",
    "        self.conv2 = GCNConv(4, 2)  # Hidden to output features\n",
    "        self.data = data\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # Pass data through the first GCN layer, then apply ReLU\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        # Pass data through the second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def nn_to_data(model: nn.Module) -> Data:\n",
    "    edges = []\n",
    "    node_features = []\n",
    "\n",
    "    # Counter for global neuron index\n",
    "    global_neuron_index = 0\n",
    "\n",
    "    # Iterate over each layer in the network\n",
    "    base = next(model.children())\n",
    "    if isinstance(base, nn.Sequential):\n",
    "        layers = base.children()\n",
    "    else:\n",
    "        layers = model.children()\n",
    "\n",
    "    if isinstance(base, nn.Sequential):\n",
    "        input_dim = base[0].in_features\n",
    "        node_features = np.zeros(input_dim)\n",
    "\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            # Update edges based on the weight matrix\n",
    "            for i in range(layer.weight.shape[1]):  # Input neurons\n",
    "                for j in range(layer.weight.shape[0]):  # Output neurons\n",
    "                    edges.append((global_neuron_index + i, global_neuron_index + layer.weight.shape[1] + j))\n",
    "            \n",
    "            # Update node features (e.g., biases)\n",
    "            extension = layer.bias.detach().numpy()\n",
    "            node_features = np.append(node_features, extension)\n",
    "            \n",
    "            # Update the global neuron index\n",
    "            global_neuron_index += layer.weight.shape[1]\n",
    "\n",
    "    # Convert lists to PyTorch tensors\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(node_features, dtype=torch.float).view(-1, 1)\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data = nn_to_data(agent.model)\n",
    "gcn = GCN(data)\n",
    "# data.x.shape, data.edge_index.shape\n",
    "# print(data.x)\n",
    "\n",
    "#Debug\n",
    "out_of_bounds = data.edge_index >= data.x.shape[0]\n",
    "if out_of_bounds.any():\n",
    "    print(\"Out-of-bounds indices found at locations:\")\n",
    "    print(data.edge_index[:, out_of_bounds.any(dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([134, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     12\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#TODO: fill this out\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()         \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()        \u001b[38;5;66;03m# Update weights\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not int"
     ]
    }
   ],
   "source": [
    "# Dataset generation\n",
    "random_r_funcs = \n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    gcn.train()\n",
    "    optimizer.zero_grad()   # Clear gradients\n",
    "    out = gcn.forward(data)       # Forward pass\n",
    "    print(out.shape)\n",
    "\n",
    "    answer = 0 #TODO: fill this out\n",
    "    loss = criterion(out, answer)  # Compute loss\n",
    "    loss.backward()         # Backward pass\n",
    "    optimizer.step()        # Update weights\n",
    "\n",
    "    # Optional: Print loss every X epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
