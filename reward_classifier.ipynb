{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox as mdpt, numpy as np\n",
    "import mdptoolbox.example\n",
    "import MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, given a transition function and discount rate, we generate a random reward function over all transitions. We then sparsify the reward function by setting some proportion (e.g. 10%) of the transition values to 0. We then generate the optimal policy for said reward function (using, for instance, policy iteration). We now attempt to build a model that can predict the sparsity used to generate the optimal policy given the transition function, discount rate, and policy itself, but *not* the reward function, as otherwise the problem would be trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a bunch of MDPs with different parameters, sparsity\n",
    "\n",
    "NUM_MDPs = 1000\n",
    "NUM_STATES = 10\n",
    "NUM_ACTIONS = 4\n",
    "\n",
    "def get_transition_matrix(num_states, num_actions, generator = np.random.dirichlet):\n",
    "    \"\"\"\n",
    "    Returns a transition matrix for a given number of states and actions\n",
    "    \n",
    "    Returns:\n",
    "        P: (num_actions, num_states, num_states) array, where P[a, s, s'] is the probability of \n",
    "        transitioning from state s to state s' given action a\n",
    "    \"\"\"\n",
    "    P = np.zeros((num_actions, num_states, num_states)) # (A, S, S) shape\n",
    "    for a in range(num_actions):\n",
    "        for s in range(num_states):\n",
    "            P[a, s, :] = generator(np.ones(num_states))\n",
    "    return P\n",
    "\n",
    "def get_reward_matrix(num_states, num_actions, sparsity = 0.0, generator = np.random.normal,\n",
    "                      only_pos_rewards = False):\n",
    "    \"\"\"\n",
    "    Returns a reward matrix for a given number of states and actions\n",
    "    [Fix 2/27/24: sparsity should be deterministic, while sparse rewards should be in random order]\n",
    "    \"\"\"\n",
    "    num_sparse_rewards = int(sparsity * num_actions * num_states ** 2)\n",
    "    rewards = np.array([(0 if i < num_sparse_rewards else (abs(generator()) if only_pos_rewards else generator())) \n",
    "                        for i in range(num_actions * num_states ** 2)])\n",
    "    np.random.shuffle(rewards)\n",
    "    return rewards.reshape((num_actions, num_states, num_states))\n",
    "\n",
    "def get_reward_matrix_variance(num_states, num_actions, variance_level = 0.0, sparse_var = 10.0, dense_var = 1.0, \n",
    "                               generator = np.random.normal, only_pos_rewards = False):\n",
    "    \"\"\"\n",
    "    Returns a reward matrix for a given number of states and actions\n",
    "    Coherent/sparse rewards are generated with a higher variance\n",
    "    \"\"\"\n",
    "    num_var_rewards = int(variance_level * num_actions * num_states ** 2)\n",
    "    rewards = np.array([((generator(0, sparse_var) if not only_pos_rewards else abs(generator(0, sparse_var))) if i < num_var_rewards else \n",
    "                        (generator(0, sparse_var) if not only_pos_rewards else abs(generator(0, sparse_var))))\n",
    "                        for i in range(num_actions * num_states ** 2)])\n",
    "    np.random.shuffle(rewards)\n",
    "    return rewards.reshape((num_actions, num_states, num_states))\n",
    "\n",
    "DISCOUNT = 0.9\n",
    "EPSILON = 0.01 # roughly indicates the \"skill level\" of the agent\n",
    "MAX_ITER = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparsity levels generated by generate_tests are divided using arange from 0 to 1 and then scrambled randomly, meaning that in effect each sparsity level in the training and test sets is sampled uniformly from [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tests(num_mdps = NUM_MDPs, sparsity_levels = None, mdp_generator = mdpt.mdp.PolicyIteration, \n",
    "                   P_generator = None, var_or_sparsity = \"sparsity\", only_pos_rewards = False):\n",
    "    \"\"\"\n",
    "    Generate a bunch of MDPs with different sparsity levels, and return the sparsity levels and the MDPs\n",
    "\n",
    "    Args:\n",
    "        sparsity_levels: a list of sparsity levels to generate MDPs with\n",
    "    Returns:\n",
    "        sparsity_levels: the sparsity levels used to generate the MDPs, in the same order as the MDPs\n",
    "        MDPS: an array of MDPs\n",
    "    \"\"\"\n",
    "    sparsity_levels = sparsity_levels if sparsity_levels is not None else np.arange(num_mdps) / num_mdps\n",
    "    sparsity_copy = sparsity_levels.copy() # defensive copy\n",
    "    np.random.shuffle(sparsity_copy)\n",
    "    reward_matrix = get_reward_matrix_variance if var_or_sparsity == \"variance\" else get_reward_matrix\n",
    "    MDPS = np.array([mdp_generator(\n",
    "        get_transition_matrix(NUM_STATES, NUM_ACTIONS) if P_generator is None else P_generator(NUM_STATES, NUM_ACTIONS), \n",
    "        reward_matrix(NUM_STATES, NUM_ACTIONS, sparsity_copy[i], only_pos_rewards = only_pos_rewards), \n",
    "        DISCOUNT, max_iter = MAX_ITER) \n",
    "        for i in range(num_mdps)\n",
    "    ])\n",
    "    return sparsity_copy, MDPS\n",
    "\n",
    "sparsity_levels, MDPS = generate_tests()\n",
    "for mdp in MDPS:\n",
    "    mdp.run()\n",
    "    # print(mdp.policy) # debug\n",
    "# print(MDPS[0].policy) # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.0712 - mae: 0.2152 - val_loss: 0.0444 - val_mae: 0.1761\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0439 - mae: 0.1710 - val_loss: 0.0378 - val_mae: 0.1597\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0384 - mae: 0.1598 - val_loss: 0.0381 - val_mae: 0.1626\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0351 - mae: 0.1533 - val_loss: 0.0408 - val_mae: 0.1686\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0324 - mae: 0.1468 - val_loss: 0.0403 - val_mae: 0.1685\n",
      "Mean squared error: 0.04151206620225779, sample size: 1000\n",
      "Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...\n"
     ]
    }
   ],
   "source": [
    "### Idea 1: neural network\n",
    "# Thanks again ChatGPT for outlining the code structure\n",
    "\n",
    "def fixed_P_generator(num_states, num_actions):\n",
    "    \"\"\"\n",
    "    Returns a fixed transition matrix for a given number of states and actions\n",
    "    (Ideally something we hope will give interesting results, like having some states be absorbing)\n",
    "    \"\"\"\n",
    "    P = np.zeros((num_actions, num_states, num_states)) # (A, S, S') shape\n",
    "    for a in range(num_actions):\n",
    "        for s in range(num_states):\n",
    "            P[a, s, (s + 1) % num_states] = 1\n",
    "    return P\n",
    "\n",
    "def sparse_P_generator(num_states, num_actions):\n",
    "    \"\"\"\n",
    "    Returns a sparse transition matrix for a given number of states and actions\n",
    "    \n",
    "    Returns:\n",
    "        P: (num_actions, num_states, num_states) array, where P[a, s, s'] is the probability of \n",
    "        transitioning from state s to state s' given action a\n",
    "    \"\"\"\n",
    "    P = np.zeros((num_actions, num_states, num_states)) # (A, S, S') shape\n",
    "    for a in range(num_actions):\n",
    "        for s in range(num_states):\n",
    "            P[a, s, np.random.randint(num_states)] = 1\n",
    "    return P\n",
    "\n",
    "sparsity, MDPs = generate_tests(10000, P_generator = sparse_P_generator)\n",
    "# print(np.array(MDPs[0].P).shape)\n",
    "training_data = [(np.array(mdp.P), mdp.discount, mdp.policy, sparsity[i]) for i, mdp in enumerate(MDPs)]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Feature extraction function\n",
    "def extract_features(transition_function, discount_rate, optimal_policy):\n",
    "    \"\"\"\n",
    "    Extract features from the MDP's transition function, discount rate, and optimal policy\n",
    "    \"\"\"\n",
    "    # opt_policy = optimal_policy.reshape(-1, 1)  # Reshape for sklearn which expects 2D input\n",
    "\n",
    "    # # Initialize the OneHotEncoder\n",
    "    # encoder = OneHotEncoder(sparse=False)  # Use sparse=False to get a dense array\n",
    "\n",
    "    # # Fit and transform\n",
    "    # opt_policy_one_hot = encoder.fit_transform(opt_policy)\n",
    "\n",
    "    features = np.concatenate((transition_function.flatten(), [discount_rate], optimal_policy.flatten()))\n",
    "    # print(features.shape)\n",
    "    # length A*S*S + 1 + A*S\n",
    "\n",
    "    # Placeholder features\n",
    "    # features = np.random.rand(411)\n",
    "\n",
    "    # Policy-only features\n",
    "    # features = optimal_policy\n",
    "    return features\n",
    "\n",
    "# Step 2: Data preparation (assuming you have your data in an appropriate format)\n",
    "# This is a placeholder function - you would replace it with actual data loading and processing\n",
    "def prepare_data(training_data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for transition_function, discount_rate, optimal_policy, sparsity_level in training_data:\n",
    "        features.append(extract_features(transition_function, discount_rate, optimal_policy))\n",
    "        labels.append(sparsity_level)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Step 3: Model selection\n",
    "\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='linear')  # Linear activation for regression output\n",
    "    ])\n",
    "\n",
    "    # Num parameters: 411*64 + 64 + 64*64 + 64 + 64*64 + 64 + 64*1 + 1 = ~26500\n",
    "    # Num data points: 100000\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error',  # Suitable for regression\n",
    "                  metrics=['mae'])  # Mean Absolute Error as an additional metric\n",
    "    # ``loss\" refers to training data, ``val_loss\" refers to validation data\n",
    "    return model\n",
    "\n",
    "features, labels = prepare_data(training_data)\n",
    "# Example: features shape is (num_samples, num_features), adjust 'input_dim' accordingly\n",
    "input_dim = features.shape[1]  # Assuming 'features' is already defined and preprocessed\n",
    "\n",
    "model = build_model(input_dim)\n",
    "\n",
    "# Training the model\n",
    "model.fit(features, labels, epochs=100, validation_split=0.2, verbose = 1, \n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Don't forget to preprocess your new data before making predictions\n",
    "# predicted_sparsity = model.predict(new_features)\n",
    "\n",
    "# Step 5: Prediction function\n",
    "def predict_sparsity(transition_function, discount_rate, optimal_policy):\n",
    "    features = extract_features(transition_function, discount_rate, optimal_policy).reshape(1, -1)\n",
    "    predicted_sparsity = model(features) # more efficient than .predict() for single samples\n",
    "    return predicted_sparsity\n",
    "\n",
    "# Testing model\n",
    "test_sparsity, test_MDPs = generate_tests(10000, P_generator=sparse_P_generator)\n",
    "test_data = [(np.array(mdp.P), mdp.discount, mdp.policy) for mdp in (test_MDPs)]\n",
    "NUM_TESTS = 1000\n",
    "mse = np.zeros(min(NUM_TESTS, len(test_data)))\n",
    "\n",
    "for i in range(min(NUM_TESTS, len(test_data))):\n",
    "    transition_function, discount_rate, optimal_policy = test_data[i]\n",
    "    prediction = predict_sparsity(transition_function, discount_rate, optimal_policy)[0][0]\n",
    "    mse[i] = (prediction - test_sparsity[i])**2\n",
    "    # print(f\"Predicted sparsity level for MDP {i+1}: {prediction}, actual sparsity level: {test_sparsity[i]}, Squared error: {mse[i]}\")\n",
    "\n",
    "print(f\"Mean squared error: {np.mean(mse)}, sample size: {min(NUM_TESTS, len(test_data))}\")\n",
    "print(\"Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ten actions:\n",
    "- As a control, when the input layer (with same dimension as transition_function + discount rate + optimal policy) is randomized, MSE = ~0.115\n",
    "- I should also note that I'm choosing hyperparameters here in a rather unprincipled way by guess-timating their effects on the model\n",
    "- The loss seems to settle around 0.033 after ~20% into each epoch when given 10^5 training points \n",
    "    - Maybe there's some sort of irreducible randomness going on when you randomize the reward function and don't pass it into the models?\n",
    "- When reward is defined over (A, S, S') (i.e. all transitions) instead of state-action pairs, loss rises to ~0.076, i.e. basically random\n",
    "\n",
    "With 100 actions:\n",
    "- ~~Model does slightly better (now ~0.028); maybe patterns in MDP/sparsity become more apparent with more states?~~ There was an error in how I calculated the MSE here, so now I'm not sure\n",
    "- In terms of computation, generating the MDPs takes a lot longer than training the model\n",
    "    - Increasing epsilon doesn't improve MDP generation/solving time (it actually makes it worse for some reason); I assume then that most of the calculation is in generating the MDPs themselves\n",
    "\n",
    "With deterministic MDPs: \n",
    "- I initially had an error that made the validation and test loss very different; it turns out that my test set was from denser MDPs, which actually tells us that the those respective models are fundamentally different\n",
    "- Even when the reward function is defined over transitions, the models with deterministic MDPs approach ~0.033 (as we would expect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.03490242308421741\n",
      "Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...\n",
      "Mean absolute error: 0.14758464850651995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04306978, -0.04014652, -0.03965629, -0.04077469, -0.04082115,\n",
       "       -0.03976853, -0.03893425, -0.03873499, -0.04249063, -0.04097574])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Idea 2: Multiple linear regression \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def extract_features(transition_function, discount_rate, optimal_policy):\n",
    "    \"\"\"\n",
    "    Extract features from the MDP's transition function, discount rate, and optimal policy\n",
    "    \"\"\"\n",
    "    # features = np.concatenate((transition_function.flatten(), [discount_rate], optimal_policy.flatten()))\n",
    "    features = optimal_policy\n",
    "    return features\n",
    "\n",
    "sparsity, MDPs = generate_tests(10000, P_generator = sparse_P_generator)\n",
    "# print(np.array(MDPs[0].P).shape)\n",
    "training_data = [(np.array(mdp.P), mdp.discount, mdp.policy, sparsity[i]) for i, mdp in enumerate(MDPs)]\n",
    "# print(sparsity)\n",
    "features, labels = prepare_data(training_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean squared error: {mse}\")\n",
    "print(\"Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...\")\n",
    "print(f\"Mean absolute error: {mae}\")\n",
    "\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interesting! When I increased the number of states from 10 to 100 and *decreased* the number of training data points from 10^5 to 10^4, test loss *decreased* from ~0.033 to ~0.014 and stayed that way with training data = 10^3\n",
    "- When I increased the number of actions from 4 to 40, both training methods got higher MSE (~0.07) with 1000 data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 4s 7ms/step - loss: 0.0885 - mae: 0.2431 - val_loss: 0.0418 - val_mae: 0.1686\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0467 - mae: 0.1773 - val_loss: 0.0365 - val_mae: 0.1540\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0421 - mae: 0.1661 - val_loss: 0.0353 - val_mae: 0.1498\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0394 - mae: 0.1607 - val_loss: 0.0341 - val_mae: 0.1459\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0365 - mae: 0.1527 - val_loss: 0.0331 - val_mae: 0.1445\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0356 - mae: 0.1519 - val_loss: 0.0332 - val_mae: 0.1456\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0353 - mae: 0.1501 - val_loss: 0.0343 - val_mae: 0.1454\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0343 - mae: 0.1492 - val_loss: 0.0337 - val_mae: 0.1453\n",
      "[(0.7074, 0.6317900612971554, 0.6317900612971554), (0.0398, 0.29808888874576056, 0.29808888874576056), (0.8858, 0.5393718413223024, 0.5393718413223025), (0.7344, 0.6206758799947386, 0.6206758799947386), (0.0505, 0.35954237502618147, 0.3595423750261816), (0.1539, 0.632874573268676, 0.632874573268676), (0.8491, 0.7700441493010938, 0.7700441493010938), (0.6203, 0.36663316561725523, 0.36663316561725523), (0.2993, 0.25877315940029944, 0.2587731594002993), (0.9012, 0.739812277512853, 0.739812277512853)]\n",
      "Linear regression:\n",
      "Mean squared error: 0.03204490490503865\n",
      "Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...\n",
      "Mean absolute error: 0.14189683452151353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.06933592, -0.09891014, -0.09879985, -0.09483585, -0.06172479,\n",
       "        -0.08538418, -0.09635115, -0.09529149, -0.06706835, -0.0913653 ,\n",
       "        -0.09194442, -0.09064689, -0.06276526, -0.08421077, -0.08929158,\n",
       "        -0.09045069, -0.07282011, -0.09955749, -0.09411468, -0.09492564,\n",
       "        -0.07352159, -0.07047249, -0.0947746 , -0.08861097, -0.07493727,\n",
       "        -0.09890601, -0.1027882 , -0.09765226, -0.0712478 , -0.09460538,\n",
       "        -0.09854439, -0.08946201, -0.07123492, -0.08570229, -0.08671676,\n",
       "        -0.08818883, -0.07532073, -0.08574614, -0.10410712, -0.09781005]),\n",
       " 1.0133928824772653)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Idea 3: hand-crafted features\n",
    "\n",
    "NUM_ACTIONS = 5\n",
    "NUM_TRAINING_SAMPLES = 10000\n",
    "from sklearn.preprocessing import OneHotEncoder, normalize\n",
    "def extract_features(transition_function, discount_rate, optimal_policy):\n",
    "    \"\"\"\n",
    "    Extract features from the MDP's transition function, discount rate, and optimal policy\n",
    "    Test features that I think might be relevant\n",
    "    - Sparsity of the transition function\n",
    "    - Number and length of loops\n",
    "    - Distance to loops/absorbing states\n",
    "    - Number of absorbing states\n",
    "    - Number of states that are never visited\n",
    "    - Number of states with lots of outward transitions\n",
    "    \"\"\"\n",
    "    transition_sparsity = np.mean(transition_function == 0)\n",
    "    num_loops = 0\n",
    "    loop_lengths = []\n",
    "    for s in range(transition_function.shape[1]):\n",
    "        exists_loop = [transition_function[a, s, s] > 0.5 for a in range(transition_function.shape[0])]\n",
    "        a = np.argmax(exists_loop)\n",
    "        if exists_loop[a]:\n",
    "            # checking if there exists an action that leads to the same state with probability > 0.5\n",
    "            num_loops += 1\n",
    "            loop_length = 1\n",
    "            next_state = np.argmax(transition_function[a, s, :])\n",
    "            while next_state != s:\n",
    "                loop_length += 1\n",
    "                next_state = np.argmax(transition_function[a, next_state, :])\n",
    "            loop_lengths.append(loop_length)\n",
    "    avg_loop_length = np.mean(loop_lengths) if len(loop_lengths) > 0 else 0\n",
    "\n",
    "    # Policy features\n",
    "    encoder = OneHotEncoder(sparse = False, drop = 'first')\n",
    "    # Drop first to avoid multicollinearity, large coefficients\n",
    "    encoder.fit(np.arange(NUM_ACTIONS).reshape(-1, 1))\n",
    "    # print(encoder.categories_)\n",
    "    # print(optimal_policy)\n",
    "    optimal_policy = encoder.transform(optimal_policy.reshape(-1, 1)).reshape(-1)\n",
    "    # in features[0:4] we have the one-hot encoding of the first action (only one of them is 1)\n",
    "    features = optimal_policy\n",
    "    # features = \n",
    "\n",
    "    # features = normalize(np.array([transition_sparsity, num_loops, avg_loop_length]).reshape(-1, 1), axis=0).reshape(-1)\n",
    "    # features = np.append(np.array([transition_sparsity, num_loops, avg_loop_length]), optimal_policy)\n",
    "    # features = np.concatenate((transition_function.flatten(), [discount_rate]))\n",
    "    # print(features)\n",
    "    return features\n",
    "\n",
    "### Neural network\n",
    "# Data generation\n",
    "sparsity, MDPs = generate_tests(NUM_TRAINING_SAMPLES, P_generator = fixed_P_generator)\n",
    "# print(np.array(MDPs[0].P).shape)\n",
    "training_data = [(np.array(mdp.P), mdp.discount, mdp.policy, sparsity[i]) for i, mdp in enumerate(MDPs)]\n",
    "\n",
    "features, labels = prepare_data(training_data)\n",
    "# Example: features shape is (num_samples, num_features), adjust 'input_dim' accordingly\n",
    "input_dim = features.shape[1]  # Assuming 'features' is already defined and preprocessed\n",
    "\n",
    "model = build_model(input_dim)\n",
    "\n",
    "# Training the model\n",
    "model.fit(features, labels, epochs=100, validation_split=0.2, verbose = 1, \n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "# print([(labels[i], model.predict(features[i].reshape(1, -1))) for i in range(10)])\n",
    "\n",
    "\n",
    "### Multiple linear regression\n",
    "features, labels = prepare_data(training_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a model\n",
    "model_lin = LinearRegression()\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_lin.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print([(y_test[i], y_pred[i], sum(X_test[i] * model_lin.coef_) + model_lin.intercept_) for i in range(10)])\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Linear regression:\")\n",
    "print(f\"Mean squared error: {mse}\")\n",
    "print(\"Expected squared error: when x, y ~ U[0, 1], E[(x-y)^2] = 1/12 = 0.0833...\")\n",
    "print(f\"Mean absolute error: {mae}\")\n",
    "\n",
    "# show the coefficients\n",
    "model_lin.coef_, model_lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all the fixed MDPs are equal\n",
    "assert all([np.array_equal(mdp[0], training_data[0][0]) for mdp in training_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tossing in only features of the MDP (loop length, etc.) doesn't seem to help (~near-random MSE), but including the policy immediately jumps to 0.033 again\n",
    "- On linear regression when one-hot encoding is applied to just the optimal policy, the coefficients are the same for every chunk of four elements, and they're all very large (magnitude ~1E10-5E12) for some reason\n",
    "- Training on just the transition function + discount rate gives basically random results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Saving coefficient outputs\\nFirst run:\\narray([-1.30675583e+11, -1.30675583e+11, -1.30675583e+11, -1.30675583e+11,\\n        2.25297886e+11,  2.25297886e+11,  2.25297886e+11,  2.25297886e+11,\\n       -1.25434170e+10, -1.25434170e+10, -1.25434170e+10, -1.25434170e+10,\\n        7.59830556e+11,  7.59830556e+11,  7.59830556e+11,  7.59830556e+11,\\n        2.88124182e+11,  2.88124182e+11,  2.88124182e+11,  2.88124182e+11,\\n       -2.20636912e+12, -2.20636912e+12, -2.20636912e+12, -2.20636912e+12,\\n        1.17074647e+12,  1.17074647e+12,  1.17074647e+12,  1.17074647e+12,\\n       -1.08094503e+12, -1.08094503e+12, -1.08094503e+12, -1.08094503e+12,\\n        4.57643503e+11,  4.57643503e+11,  4.57643503e+11,  4.57643503e+11,\\n       -1.72875563e+12, -1.72875563e+12, -1.72875563e+12, -1.72875563e+12])\\nSecond run:\\narray([ 6.42943536e+10,  6.42943536e+10,  6.42943536e+10,  6.42943536e+10,\\n        4.38543769e+10,  4.38543769e+10,  4.38543769e+10,  4.38543769e+10,\\n        1.25801626e+11,  1.25801626e+11,  1.25801626e+11,  1.25801626e+11,\\n        2.11727524e+11,  2.11727524e+11,  2.11727524e+11,  2.11727524e+11,\\n        2.01145141e+09,  2.01145141e+09,  2.01145141e+09,  2.01145141e+09,\\n       -7.43402751e+11, -7.43402751e+11, -7.43402751e+11, -7.43402751e+11,\\n        8.19022461e+11,  8.19022461e+11,  8.19022461e+11,  8.19022461e+11,\\n       -2.38391058e+12, -2.38391058e+12, -2.38391058e+12, -2.38391058e+12,\\n        5.12756087e+11,  5.12756087e+11,  5.12756087e+11,  5.12756087e+11,\\n       -1.69323492e+11, -1.69323492e+11, -1.69323492e+11, -1.69323492e+11])\\nAfter fixing multicollinearity:\\n(array([-0.06926151, -0.08675559, -0.10041903, -0.07555895, -0.09954824,\\n        -0.10887027, -0.06850544, -0.08640547, -0.09076514, -0.05552694,\\n        -0.08782644, -0.09442183, -0.08313579, -0.10442827, -0.1021993 ,\\n        -0.06599209, -0.08373147, -0.09186291, -0.07417732, -0.10491376,\\n        -0.10016291, -0.07514404, -0.08543159, -0.09656789, -0.06529272,\\n        -0.08765322, -0.10928858, -0.08787039, -0.10028769, -0.09871483]),\\n intercept = 0.9679213745503301)\\n\\n TODO: implement automated hyperparameter tuning\\n'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Saving coefficient outputs\n",
    "First run:\n",
    "array([-1.30675583e+11, -1.30675583e+11, -1.30675583e+11, -1.30675583e+11,\n",
    "        2.25297886e+11,  2.25297886e+11,  2.25297886e+11,  2.25297886e+11,\n",
    "       -1.25434170e+10, -1.25434170e+10, -1.25434170e+10, -1.25434170e+10,\n",
    "        7.59830556e+11,  7.59830556e+11,  7.59830556e+11,  7.59830556e+11,\n",
    "        2.88124182e+11,  2.88124182e+11,  2.88124182e+11,  2.88124182e+11,\n",
    "       -2.20636912e+12, -2.20636912e+12, -2.20636912e+12, -2.20636912e+12,\n",
    "        1.17074647e+12,  1.17074647e+12,  1.17074647e+12,  1.17074647e+12,\n",
    "       -1.08094503e+12, -1.08094503e+12, -1.08094503e+12, -1.08094503e+12,\n",
    "        4.57643503e+11,  4.57643503e+11,  4.57643503e+11,  4.57643503e+11,\n",
    "       -1.72875563e+12, -1.72875563e+12, -1.72875563e+12, -1.72875563e+12])\n",
    "Second run:\n",
    "array([ 6.42943536e+10,  6.42943536e+10,  6.42943536e+10,  6.42943536e+10,\n",
    "        4.38543769e+10,  4.38543769e+10,  4.38543769e+10,  4.38543769e+10,\n",
    "        1.25801626e+11,  1.25801626e+11,  1.25801626e+11,  1.25801626e+11,\n",
    "        2.11727524e+11,  2.11727524e+11,  2.11727524e+11,  2.11727524e+11,\n",
    "        2.01145141e+09,  2.01145141e+09,  2.01145141e+09,  2.01145141e+09,\n",
    "       -7.43402751e+11, -7.43402751e+11, -7.43402751e+11, -7.43402751e+11,\n",
    "        8.19022461e+11,  8.19022461e+11,  8.19022461e+11,  8.19022461e+11,\n",
    "       -2.38391058e+12, -2.38391058e+12, -2.38391058e+12, -2.38391058e+12,\n",
    "        5.12756087e+11,  5.12756087e+11,  5.12756087e+11,  5.12756087e+11,\n",
    "       -1.69323492e+11, -1.69323492e+11, -1.69323492e+11, -1.69323492e+11])\n",
    "After fixing multicollinearity:\n",
    "(array([-0.06926151, -0.08675559, -0.10041903, -0.07555895, -0.09954824,\n",
    "        -0.10887027, -0.06850544, -0.08640547, -0.09076514, -0.05552694,\n",
    "        -0.08782644, -0.09442183, -0.08313579, -0.10442827, -0.1021993 ,\n",
    "        -0.06599209, -0.08373147, -0.09186291, -0.07417732, -0.10491376,\n",
    "        -0.10016291, -0.07514404, -0.08543159, -0.09656789, -0.06529272,\n",
    "        -0.08765322, -0.10928858, -0.08787039, -0.10028769, -0.09871483]),\n",
    " intercept = 0.9679213745503301)\n",
    "\n",
    " TODO: implement automated hyperparameter tuning\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\sparsity_prediction\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "### Idea 3.5: Hyperparameter tuning\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(n_layers=1, n_units=64, dropout_rate=0.5, learning_rate=0.001, input_dim = NUM_STATES * (NUM_ACTIONS - 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_units, activation='relu', input_shape=(input_dim,)))  # Assuming input_shape is defined\n",
    "    for _ in range(n_layers - 1):\n",
    "        model.add(Dense(n_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification or regression\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='mean_squared_error',  # or 'mean_squared_error' for regression\n",
    "                  metrics=['accuracy'])  # or other metrics for regression\n",
    "    return model\n",
    "\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        return build_model(\n",
    "            n_layers=hp.Int('n_layers', 1, 5),  # Number of layers\n",
    "            n_units=hp.Int('n_units', 32, 256),  # Number of units per layer\n",
    "            dropout_rate=hp.Float('dropout_rate', 0.1, 0.5),  # Dropout rate\n",
    "            learning_rate=hp.Float('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "        )\n",
    "\n",
    "hypermodel = MyHyperModel()\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',  # or 'val_accuracy' for classification\n",
    "    max_trials=20,  # Number of trials to run\n",
    "    executions_per_trial=2,  # Number of models to build and fit for each trial\n",
    "    directory='my_dir',  # Directory to save logs and models\n",
    "    project_name='sparsity_prediction'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.08041135458219313, mean absolute error: 0.24394241106752718\n",
      "Mean squared error: 0.04654428173014684, mean absolute error: 0.17532788010060416\n"
     ]
    }
   ],
   "source": [
    "### Testing variance definition of coherence, only positive rewards\n",
    "\n",
    "### Neural network\n",
    "# Data generation\n",
    "sparsity1, MDPs1 = generate_tests(NUM_TRAINING_SAMPLES, P_generator = sparse_P_generator, \n",
    "                                  var_or_sparsity = \"variance\")\n",
    "sparsity2, MDPs2 = generate_tests(NUM_TRAINING_SAMPLES, P_generator = sparse_P_generator,\n",
    "                                  only_pos_rewards = True)\n",
    "\n",
    "features1, labels1 = prepare_data([(np.array(mdp.P), mdp.discount, mdp.policy, sparsity1[i]) for i, mdp in enumerate(MDPs1)])\n",
    "features2, labels2 = prepare_data([(np.array(mdp.P), mdp.discount, mdp.policy, sparsity2[i]) for i, mdp in enumerate(MDPs2)])\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, labels1, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(features2, labels2, test_size=0.2, random_state=42)\n",
    "model_var = LinearRegression()\n",
    "model_pos = LinearRegression()\n",
    "model_var.fit(X_train1, y_train1)\n",
    "model_pos.fit(X_train2, y_train2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred1 = model_var.predict(X_test1)\n",
    "y_pred2 = model_pos.predict(X_test2)\n",
    "\n",
    "# Evaluate the model\n",
    "mse1 = mean_squared_error(y_test1, y_pred1)\n",
    "mae1 = mean_absolute_error(y_test1, y_pred1)\n",
    "print(f\"Mean squared error: {mse1}, mean absolute error: {mae1}\")\n",
    "mse2 = mean_squared_error(y_test2, y_pred2)\n",
    "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
    "print(f\"Mean squared error: {mse2}, mean absolute error: {mae2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naively forcing all rewards to be positive via the abs() function decreases classifier accuracy\n",
    "- Naively using the variance definition of coherence destroys classifier accuracy (although I'm probably not doing it right), regardless of whether abs() is used or not\n",
    "    - Not sure why this is happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.0967 - mae: 0.2630 - val_loss: 0.0871 - val_mae: 0.2542\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0887 - mae: 0.2556 - val_loss: 0.0844 - val_mae: 0.2509\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0856 - mae: 0.2520 - val_loss: 0.0841 - val_mae: 0.2502\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0848 - mae: 0.2520 - val_loss: 0.0846 - val_mae: 0.2512\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0844 - mae: 0.2513 - val_loss: 0.0843 - val_mae: 0.2507\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0845 - mae: 0.2516 - val_loss: 0.0846 - val_mae: 0.2512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca3be9fe20>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Neural network\n",
    "# Data generation\n",
    "sparsity, MDPs = generate_tests(NUM_TRAINING_SAMPLES, P_generator = fixed_P_generator,\n",
    "                                var_or_sparsity=\"variance\")\n",
    "# print(np.array(MDPs[0].P).shape)\n",
    "training_data = [(np.array(mdp.P), mdp.discount, mdp.policy, sparsity[i]) for i, mdp in enumerate(MDPs)]\n",
    "\n",
    "features, labels = prepare_data(training_data)\n",
    "# Example: features shape is (num_samples, num_features), adjust 'input_dim' accordingly\n",
    "input_dim = features.shape[1]  # Assuming 'features' is already defined and preprocessed\n",
    "\n",
    "model = build_model(input_dim)\n",
    "\n",
    "# Training the model\n",
    "model.fit(features, labels, epochs=100, validation_split=0.2, verbose = 1, \n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 1000: 0.09371180087327957\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 1000: 0.09146794253082274, 0.2669223046875\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 10000: 0.08359464257955551\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 10000: 0.0833858502318457, 0.25080793749999997\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 100000: 0.08333457261323929\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 100000: 0.08305501349487752, 0.24915917619921873\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 1000: 0.09832251071929932\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 1000: 0.17186699407470704, 0.34079499999999996\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 10000: 0.09385699778795242\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 10000: 0.08944895859643068, 0.254555390625\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 100000: 0.08356982469558716\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 100000: 0.08347383734873394, 0.24981407776171874\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = Dense, num_training_samples = 1000: 0.0955672413110733\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = Dense, num_training_samples = 1000: 0.13809882730712889, 0.305011875\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = Dense, num_training_samples = 10000: 0.08512832224369049\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = Dense, num_training_samples = 10000: 0.08958399641642288, 0.25725720830078125\n",
      "NN loss for coherence = variance, only_pos_rewards = False, P_generator = Dense, num_training_samples = 100000: 0.08337536454200745\n",
      "Regression model loss for variance = variance, only_pos_rewards = False, P_generator = Dense, num_training_samples = 100000: 0.08378303754395088, 0.25025641651367186\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 1000: 0.11375373601913452\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 1000: 0.09252651823516846, 0.2608850390625\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 10000: 0.0836712196469307\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 10000: 0.08443225469486816, 0.2521952484375\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 100000: 0.08333991467952728\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 100000: 0.08309490330581115, 0.24996905528906255\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 1000: 0.10238754749298096\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 1000: 0.15819313802612306, 0.317292265625\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 10000: 0.09598668664693832\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 10000: 0.08843613106703126, 0.25468776875\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 100000: 0.08378766477108002\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 100000: 0.0836629230062165, 0.2505011350625\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = Dense, num_training_samples = 1000: 0.09663588553667068\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = Dense, num_training_samples = 1000: 0.1571708692276764, 0.32683357421875003\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = Dense, num_training_samples = 10000: 0.08385069668292999\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = Dense, num_training_samples = 10000: 0.08527970986668916, 0.24980338242187503\n",
      "NN loss for coherence = variance, only_pos_rewards = True, P_generator = Dense, num_training_samples = 100000: 0.08344600349664688\n",
      "Regression model loss for variance = variance, only_pos_rewards = True, P_generator = Dense, num_training_samples = 100000: 0.08410354343670526, 0.25096635644140625\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 1000: 0.04019073769450188\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 1000: 0.031984461397399896, 0.1369848046875\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 10000: 0.036261241883039474\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 10000: 0.03443789238511322, 0.14512724023437498\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 100000: 0.03900279477238655\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = fixed_P_generator, num_training_samples = 100000: 0.03438483960413071, 0.14602647144531253\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 1000: 0.05207120627164841\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 1000: 0.0699460104649067, 0.2053046875\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 10000: 0.0422290600836277\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 10000: 0.03587713934419128, 0.14960019140625\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 100000: 0.035516854375600815\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = sparse_P_generator, num_training_samples = 100000: 0.034941491023388026, 0.14801166399218751\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = Dense, num_training_samples = 1000: 0.08538614958524704\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = Dense, num_training_samples = 1000: 0.14992516432455452, 0.3119484289550781\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = Dense, num_training_samples = 10000: 0.07944615185260773\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = Dense, num_training_samples = 10000: 0.08026686209413941, 0.24280995859374999\n",
      "NN loss for coherence = sparsity, only_pos_rewards = False, P_generator = Dense, num_training_samples = 100000: 0.07680698484182358\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = False, P_generator = Dense, num_training_samples = 100000: 0.07950195107468087, 0.24404144371484376\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 1000: 0.053974393755197525\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 1000: 0.05828228885513782, 0.19432233398437496\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 10000: 0.045754045248031616\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 10000: 0.04940878411679444, 0.18182207187500002\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 100000: 0.04574628919363022\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = fixed_P_generator, num_training_samples = 100000: 0.047166387495205575, 0.17679080380273438\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 1000: 0.06549149751663208\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 1000: 0.09819709055350781, 0.2541938037109375\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 10000: 0.052024584263563156\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 10000: 0.04908615693191895, 0.17988784624023438\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 100000: 0.04779501631855965\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = sparse_P_generator, num_training_samples = 100000: 0.04844652137052167, 0.17935681088671876\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = Dense, num_training_samples = 1000: 0.08740534633398056\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = Dense, num_training_samples = 1000: 0.15378965021687507, 0.328089375\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = Dense, num_training_samples = 10000: 0.08355750143527985\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = Dense, num_training_samples = 10000: 0.08637581110998872, 0.253019943359375\n",
      "NN loss for coherence = sparsity, only_pos_rewards = True, P_generator = Dense, num_training_samples = 100000: 0.08002922683954239\n",
      "Regression model loss for variance = sparsity, only_pos_rewards = True, P_generator = Dense, num_training_samples = 100000: 0.08186916961709191, 0.24803265609765626\n"
     ]
    }
   ],
   "source": [
    "### Search over hyperparameters of training data\n",
    "import itertools\n",
    "\n",
    "params = list(itertools.product([\"variance\", \"sparsity\"], [False, True], [fixed_P_generator, sparse_P_generator, None], [1000, 10000]))\n",
    "training_param_results = {}\n",
    "\n",
    "for param in params:\n",
    "    var_or_sparsity, only_pos_rewards, P_generator, num_training_samples = param\n",
    "    P_generator_str = P_generator.__name__ if P_generator is not None else \"Dense\"\n",
    "    # Train neural network\n",
    "    sparsity, MDPs = generate_tests(num_training_samples, P_generator = P_generator, \n",
    "                                    var_or_sparsity = var_or_sparsity, only_pos_rewards = only_pos_rewards)\n",
    "    features, labels = prepare_data([(np.array(mdp.P), mdp.discount, mdp.policy, sparsity[i]) for i, mdp in enumerate(MDPs)])\n",
    "    input_dim = features.shape[1]\n",
    "    model = build_model(input_dim)\n",
    "    model.fit(features, labels, epochs=100, validation_split=0.2, verbose = 0, \n",
    "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "    \n",
    "    # Test data set for NN, training data set for linear regression\n",
    "    sparsity2, MDPs2 = generate_tests(num_training_samples, P_generator = P_generator,\n",
    "                                    var_or_sparsity = var_or_sparsity, only_pos_rewards = only_pos_rewards)\n",
    "    training_data = [(np.array(mdp.P), mdp.discount, mdp.policy, sparsity2[i]) for i, mdp in enumerate(MDPs2)]\n",
    "    features, labels = prepare_data(training_data)\n",
    "    nn_loss = model.evaluate(features, labels, verbose=0)[0]\n",
    "    print(f\"NN loss for coherence = {var_or_sparsity}, only_pos_rewards = {only_pos_rewards}, P_generator = {P_generator_str}, num_training_samples = {num_training_samples}: {nn_loss}\")\n",
    "\n",
    "    # Train, test linear regression\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    model_lin = LinearRegression()\n",
    "    model_lin.fit(X_train, y_train)\n",
    "    y_pred = model_lin.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Regression model loss for variance = {var_or_sparsity}, only_pos_rewards = {only_pos_rewards}, P_generator = {P_generator_str}, num_training_samples = {num_training_samples}: {mse}, {mae}\")\n",
    "    \n",
    "    training_param_results[param] = (nn_loss, mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('variance',\n",
       "  False,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.09371180087327957, 0.09146794253082274),\n",
       " ('variance',\n",
       "  False,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.08359464257955551, 0.0833858502318457),\n",
       " ('variance',\n",
       "  False,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.08333457261323929, 0.08305501349487752),\n",
       " ('variance',\n",
       "  False,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.09832251071929932, 0.17186699407470704),\n",
       " ('variance',\n",
       "  False,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.09385699778795242, 0.08944895859643068),\n",
       " ('variance',\n",
       "  False,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.08356982469558716, 0.08347383734873394),\n",
       " ('variance', False, None, 1000): (0.0955672413110733, 0.13809882730712889),\n",
       " ('variance', False, None, 10000): (0.08512832224369049, 0.08958399641642288),\n",
       " ('variance', False, None, 100000): (0.08337536454200745, 0.08378303754395088),\n",
       " ('variance',\n",
       "  True,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.11375373601913452, 0.09252651823516846),\n",
       " ('variance',\n",
       "  True,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.0836712196469307, 0.08443225469486816),\n",
       " ('variance',\n",
       "  True,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.08333991467952728, 0.08309490330581115),\n",
       " ('variance',\n",
       "  True,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.10238754749298096, 0.15819313802612306),\n",
       " ('variance',\n",
       "  True,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.09598668664693832, 0.08843613106703126),\n",
       " ('variance',\n",
       "  True,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.08378766477108002, 0.0836629230062165),\n",
       " ('variance', True, None, 1000): (0.09663588553667068, 0.1571708692276764),\n",
       " ('variance', True, None, 10000): (0.08385069668292999, 0.08527970986668916),\n",
       " ('variance', True, None, 100000): (0.08344600349664688, 0.08410354343670526),\n",
       " ('sparsity',\n",
       "  False,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.04019073769450188, 0.031984461397399896),\n",
       " ('sparsity',\n",
       "  False,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.036261241883039474, 0.03443789238511322),\n",
       " ('sparsity',\n",
       "  False,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.03900279477238655, 0.03438483960413071),\n",
       " ('sparsity',\n",
       "  False,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.05207120627164841, 0.0699460104649067),\n",
       " ('sparsity',\n",
       "  False,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.0422290600836277, 0.03587713934419128),\n",
       " ('sparsity',\n",
       "  False,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.035516854375600815, 0.034941491023388026),\n",
       " ('sparsity', False, None, 1000): (0.08538614958524704, 0.14992516432455452),\n",
       " ('sparsity', False, None, 10000): (0.07944615185260773, 0.08026686209413941),\n",
       " ('sparsity', False, None, 100000): (0.07680698484182358, 0.07950195107468087),\n",
       " ('sparsity',\n",
       "  True,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.053974393755197525, 0.05828228885513782),\n",
       " ('sparsity',\n",
       "  True,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.045754045248031616, 0.04940878411679444),\n",
       " ('sparsity',\n",
       "  True,\n",
       "  <function __main__.fixed_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.04574628919363022, 0.047166387495205575),\n",
       " ('sparsity',\n",
       "  True,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  1000): (0.06549149751663208, 0.09819709055350781),\n",
       " ('sparsity',\n",
       "  True,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  10000): (0.052024584263563156, 0.04908615693191895),\n",
       " ('sparsity',\n",
       "  True,\n",
       "  <function __main__.sparse_P_generator(num_states, num_actions)>,\n",
       "  100000): (0.04779501631855965, 0.04844652137052167),\n",
       " ('sparsity', True, None, 1000): (0.08740534633398056, 0.15378965021687507),\n",
       " ('sparsity', True, None, 10000): (0.08355750143527985, 0.08637581110998872),\n",
       " ('sparsity', True, None, 100000): (0.08002922683954239, 0.08186916961709191)}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_param_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
